<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Tasks People Prompt: Supplementary Material</title>
<link rel="stylesheet" href="styles.css">
</head>
<body>
<p>&nbsp;</p>
<h1><a name="bookmark0"></a>&zwnj;Supplementary material for </h1>
<h1><a style="text-decoration: none;" href="https://arxiv.org/abs/2404.09384" target="_blank" rel="noopener">"Tasks People Prompt: A Taxonomy of LLM Downstream Tasks in Software Verification and Falsification Approaches"</a>, <br><p style="font-weight: normal; font-size: 14pt; ">by <a style="color: black; text-decoration: none;" href="https://lafhis.dc.uba.ar/~vbraber" target="_blank" rel="noopener">V&iacute;ctor A. Braberman</a>, <a style="color: black; text-decoration: none;" href="https://staff.dc.uba.ar/fbonomo/" target="_blank" rel="noopener">Flavia Bonomo-Braberman</a>, Yiannis Charalambous, Juan G. Colonna, Lucas C. Cordeiro, and <a style="color: black; text-decoration: none;" href="https://numeros.icomp.ufam.edu.br/rosiane" target="_blank" rel="noopener">Rosiane de Freitas</a></p></h1>
<p>&nbsp;</p>
<p style="padding-left: 8pt; text-indent: 0pt; text-align: left; font-size: 12pt; font-size: 12pt;"><b>Table 1:</b> SE task: Testing.</p>
<p>&nbsp;</p>
<table style="border-collapse: collapse; margin-left: 6.25pt;" cellspacing="0">
<tbody>
<tr style="height: 30pt;">
<td style="width: 99pt; border-width: 1pt; border-style: solid;" bgcolor="#C1D3E7">
<p>SE Problem</p>
</td>
<td style="width: 520pt; border-width: 1pt; border-style: solid;" bgcolor="#C1D3E7">
<p>LLM Downstream Tasks<br>(input</span>&rarr; ⟨<span class="s3">type of task </span>⟩ &rarr;output[learn. strat.])</span><span class="s4">&lowast;</span></p>
</td>
<td style="width: 320pt; border-width: 1pt; border-style: solid;" bgcolor="#C1D3E7">
<p>Architectural Notes</p>
</td>
</tr>
<tr style="height: 17pt;">
<td>
<p>Unit-Test Generation</p>
</td>
<td>
<p><span class="sBold">TestGen-LLM</span>&nbsp;<a class="s6" href="#bookmark4">[4]</a>: existing unit test class (UTC) + tested class id &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨CoverageAugmenting-Test-Extension⟩</span>&nbsp;&rarr; extended UTC.</p>

<p><span class="sBold">FSML&nbsp;</span><a class="s6" href="#bookmark6">[6]</a>: list helper meths + meth under test &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Test-Generation⟩</span>&nbsp;&rarr; (test)<span class="s9">+</span>&nbsp;[Few-Shot].</p>

<p><span class="sBold">ChatGPTTests&nbsp;</span><a class="s6" href="#bookmark7">[7]</a>: prgm &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Test-Generation⟩</span>&nbsp;&rarr; test cases (basic);</p>
<p style="padding-top: 2pt;">prgm + unit test cases (UTC) + cvrg report &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨CoverageAugmenting-Test-Extension⟩</span>&nbsp;&rarr; extended UTC.</p>

<p><span class="sBold">CodeT&nbsp;</span><a class="s6" href="#bookmark9">[9]</a>: intent + sig &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨IntentCorresponding-Test-Generation⟩</span>&nbsp;&rarr; in/out&nbsp;</span>pairs.</p>

<p><span class="sBold">ChatUniTest&nbsp;</span><a class="s6" href="#bookmark14">[14]</a>: focal-class sig + focal meth src-code + required depend + sig meth &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Test-Generation⟩</span>&nbsp;&rarr; (test)<span class="s9">1...5</span> [Adaptive focal ctxt];</p>
<p style="padding-top: 2pt;">test + error + focal meth + focal-class name + focal meth src-code &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ErrorAware-Test-Correction⟩</span>&nbsp;&rarr; (test)<span class="s9">1...5</span>.</p>

<p><span class="sBold">CodeCoT&nbsp;</span><a class="s6" href="#bookmark34">[34]</a>: funct def of unit + doc &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Basic&amp;Edge-TestCase-Generation⟩</span>&nbsp;&rarr; test cases.</p>

<p><span class="sBold">AgentCoder&nbsp;</span><a class="s6" href="#bookmark35">[35]</a>: funct def of unit + doc &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Basic&amp;Edge-TestCase-Generation⟩</span>&nbsp;&rarr; test cases.</p>

<p><span class="sBold">CodaMOSA&nbsp;</span><a class="s6" href="#bookmark50">[50]</a>: (portion) src-code under test + callable def + callable name &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Targeted-Test-Generation⟩</span>&nbsp;&rarr; test cases.</p>

<p><span class="sBold">TestChain&nbsp;</span><a class="s6" href="#bookmark52">[52]</a>: func def of unit + doc &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Basic&amp;Edge-TestInput-Generation⟩</span>&nbsp;&rarr; inputs [One-Shot];</p>
<p style="padding-top: 2pt;">func def + doc + input &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨IntentionCorresponding-Result-Generation⟩</span>&nbsp;&rarr; (requested computation)<span class="s4">&lowast;</span> + asserted value) [CoT, ReAct: request to compute the adequate output].</p>

<p><span class="sBold">CoverUp&nbsp;</span><a class="s6" href="#bookmark69">[69]</a>: code excerpt + uncovered lines &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨CoverageAugmenting-Test-Generation⟩</span>&nbsp;&rarr; tests;</p>
<p style="padding-top: 2pt;">code excerpt + test + uncovered lines + (errors) &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨CoverageAugmenting-Test-Correction⟩</span>&nbsp;&rarr; test.</p>

<p><span class="sBold">TestPilot&nbsp;</span><a class="s6" href="#bookmark73">[73]</a>: meth under test sig + (doc)<span class="s9">0...1</span> + (usage examp)<span class="s9">0...1</span> + (src-code)<span class="s9">0...1</span> + (fail test + error)</span><span class="s9">0...1</span> &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨BuildablePassable-Test-Generation⟩</span>&nbsp;&rarr; (test)<span class="s9">0...5</span>.</p>

<p><span class="sBold">EASEeval&nbsp;</span><a class="s6" href="#bookmark77">[77]</a>: meth under test name + class code + import statements &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Test-Generation⟩</span>&nbsp;&rarr; unit tests.</p>

<p><span class="sBold">TELPA&nbsp;</span><a class="s6" href="#bookmark98">[98]</a>: MUT code + method-invocation seq + examp following m-i seq + branch-relevant meth &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨CoverageAugmenting-Test-Generation⟩</span>&nbsp;&rarr; test.</p>

<p><span class="sBold">ChatTESTER&nbsp;</span><a class="s6" href="#bookmark104">[104]</a>: focal meth code &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨CodeCorresponding-Intent-Verbalization⟩</span>&nbsp;&rarr; intent;</p>
<p style="padding-top: 2pt;">focal meth sig + intent &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨IntentCorresponding-Test-Generation⟩</span>&nbsp;&rarr; unit tests;</p>
<p style="padding-top: 2pt;">unit test + error msgs &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ErrorAware-Test-Correction⟩</span>&nbsp;&rarr; unit test.</p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">TestGen-LLM&nbsp;</span><a class="s6" href="#bookmark4">[4]</a>: Generated tests are further processed in a pipeline of filtering-analysis (e.g., buildability, non-flakiness, coverage improvement) that is part of the Assured LLM-Based Software Engineering&nbsp;<a class="s6" href="#bookmark5">[5]</a> framework.</p>
<p style="text-align: justify;"><span class="sBold">FSML&nbsp;</span><a class="s6" href="#bookmark6">[6]</a>: Study on potential proficiency.</p>
<p style="text-align: justify;"><span class="sBold">ChatGPTTests&nbsp;</span><a class="s6" href="#bookmark7">[7]</a>: Study. Two alternatives: (basic) and a version that tries to improve coverage.</p>
<p style="text-align: justify;"><span class="sBold">CodeT&nbsp;</span><a class="s6" href="#bookmark9">[9]</a>: It is part of a code generation approach that includes ulterior dual execution agreement to choose the best solution.</p>
<p style="text-align: justify;"><span class="sBold">ChatUniTest&nbsp;</span><a class="s6" href="#bookmark14">[14]</a>: Prompt is adaptive to token limit and further context of dependent classes could be added based on dependency graph. CoT is mentioned but not detailed. Repair phase may also leverage an LLM.</p>
<p style="text-align: justify;"><span class="sBold">CodeCoT&nbsp;</span><a class="s6" href="#bookmark34">[34]</a>: Testing is part of a larger code generation solution.</p>
<p style="text-align: justify;"><span class="sBold">AgentCoder&nbsp;</span><a class="s6" href="#bookmark35">[35]</a>: Testing is part of a larger code generation solution.</p>
<p style="text-align: justify;"><span class="sBold">CodaMOSA&nbsp;</span><a class="s6" href="#bookmark50">[50]</a>: Use of LLMs in the context of Search-Based Software Testing. LLMs outputs require significant post-processing to be integrated into the SBST framework.</p>
<p style="text-align: justify;"><span class="sBold">TestChain&nbsp;</span><a class="s6" href="#bookmark52">[52]</a>: Designer agent and Calculator agents reported. Calculator uses Python Interpreter.</p>
<p style="text-align: justify;"><span class="sBold">CoverUp&nbsp;</span><a class="s6" href="#bookmark69">[69]</a>: Uses testing framework including coverage tool.</p>
<p style="text-align: justify;"><span class="sBold">TestPilot&nbsp;</span><a class="s6" href="#bookmark73">[73]</a>: Refiner applies strategies to include or not certain info in prompts. Adaptive nature means that LLM is (re)invoked with failing test and error message if validation fails.</p>
<p style="text-align: justify;"><span class="sBold">TELPA&nbsp;</span><a class="s6" href="#bookmark98">[98]</a>: Static preprocessing is done to identify relevant method-invocation sequences and methods relevant for branch outcomes.</p>
<p style="text-align: justify;"><span class="sBold">ChatTESTER&nbsp;</span><a class="s6" href="#bookmark104">[104]</a>: The iterative test refiner iteratively fixes the compilation errors in the tests generated by the initial test generation. This is done with parsing and analysis of components that build prompts.</p>
</td>
</tr>
<tr style="height: 105pt;">
<td>
<p>Failure-Inducing Test Generation</p>
</td>
<td>
<p><span class="sBold">DiffPrompt&nbsp;</span><a class="s6" href="#bookmark53">[53]</a>: snip &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨CodeCorresponding-Intent-Verbalization⟩</span>&nbsp;&rarr; intent;</p>
<p style="padding-top: 2pt;">intent &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨IntentCorresponding-Code-Generation⟩</span>&nbsp;&rarr; prgms;</p>
<p style="padding-top: 2pt;">prgm &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Test-Generation⟩</span>&nbsp;&rarr; test cases.</p>

<p><span class="sBold">AID&nbsp;</span><a class="s6" href="#bookmark54">[54]</a>: problem description + code &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨IntentCorresponding-Code-Correction⟩</span>&nbsp;&rarr; code;</p>
<p style="padding-top: 2pt;">problem description &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ConstraintSatisfying-InputGenerator-Generation⟩</span>&nbsp;&rarr; code.</p>

<p><span class="sBold">secTests&nbsp;</span><a class="s6" href="#bookmark111">[111]</a>: funct name + client code + vul-id + vul API ids + reference test code &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Mimicking-Test-Generation⟩</span>&nbsp;&rarr; test code on client code.</p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">DiffPrompt&nbsp;</span><a class="s6" href="#bookmark53">[53]</a>: Single interaction for intent and program generation. Multiple interactions for obtaining test cases that have same result for all generated versions.</span></p>
<p style="text-align: justify;"><span class="sBold">AID&nbsp;</span><a class="s6" href="#bookmark54">[54]</a>: The approach includes differential testing to detect bugs.</span></p>
<p style="text-align: justify;"><span class="sBold">secTests&nbsp;</span><a class="s6" href="#bookmark111">[111]</a>: Study on mimicking generic vulnerability-exploiting test given on client code.</span></p>
</td>
</tr>
<tr>
<td>
<p>Regression Testing</p>
</td>
<td>
<p><span class="sBold">SymPrompt&nbsp;</span><a class="s6" href="#bookmark72">[72]</a>: focal meth sig + type and dependency ctxt + path constr &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ConstraintSatisfying-Input-Generation⟩</span>&nbsp;&rarr; test.</p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">SymPrompt&nbsp;</span><a class="s6" href="#bookmark72">[72]</a>: Preprocessing through static analysis techniques to get paths and context.</p>
</td>
</tr>
<tr>
<td>
<p>Input Generation</p>
</td>
<td>
<p><span class="sBold">RESTGPT&nbsp;</span><a class="s6" href="#bookmark49">[49]</a>: OpenAPI spec &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨DescriptionCorresponding-Liberal-Constraint-Characterization⟩</span>&nbsp;&rarr; struct with constrs, types, format for params [Few-Shot];</p>
<p style="padding-top: 2pt;">OpenAPI spec + prev conv &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ConstraintSatisfying-Input-Generation⟩</span>&nbsp;&rarr; examp for param [Few-Shot].</p>

<p><span class="sBold">InputBlaster&nbsp;</span><a class="s6" href="#bookmark59">[59]</a>: local&amp;global ctxt + NL candidate constrs + (dynamic hint) &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨GUIInputCorresponding-ValidityConstraint-Characterization⟩</span>&nbsp;&rarr; inferred constr [Few-Shot];</p>
<p style="padding-top: 2pt;">prev conv + inf constr &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Valid-GUIInput-Generation⟩</span>&nbsp;&rarr; valid input + inferred constr [Few-Shot];</p>
<p style="padding-top: 2pt;">valid input + inferred constr + retrv examp of unusual bug-trigg inputs + (test-exec fdbk on mutant) &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨Effective&amp;Diversified-MutationRule-Characterization⟩</span>&nbsp;&rarr; mutation rule [Few-Shot];</p>
<p style="padding-top: 2pt;">mutation rule + (test-exec fdbk on prev generator) &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨InputGenerator-Generation⟩</span>&nbsp;&rarr; test-input generator [Few-Shot].</p>

<p><span class="sBold">PBT-GPT&nbsp;</span><a class="s6" href="#bookmark88">[88]</a>: API doc + focus meth name &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Postcondition-Assertion-Generation⟩</span>&nbsp;&rarr; prop assertions;</p>
<p style="padding-top: 2pt;">API doc + focus meth name &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨InputGenerator-Generation⟩</span>&nbsp;&rarr; gen funct;</p>
<p style="padding-top: 2pt;">API doc + focus meth name + gen funct conv &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ParametrizedTest-Generation⟩</span>&nbsp;&rarr; prop-based test;</p>
<p style="padding-top: 2pt;">API doc + focus meth name &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨PropertyBasedTest-Generation⟩</span>&nbsp;&rarr; prop-based test.</p>

<p><span class="sBold">mrDetector&nbsp;</span><a class="s6" href="#bookmark95">[95]</a>: shop name + shop type &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨LikelyRecalling-Data-Generation⟩</span>&nbsp;&rarr; searching keywords [Few-Shot, CoT];</p>
<p style="padding-top: 2pt;">shop name + shop type + potential recalling sentence &rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Answer-Quality(Reasonability)-Judgment⟩</span>&nbsp;&rarr; yes/no [Few-Shot].</p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">RESTGPT&nbsp;</span><a class="s6" href="#bookmark49">[49]</a>: Improves the treatment of OpenAPI spec, particularly human-readable part. Both tasks are actually performed in a single prompt. </p>
<p style="text-align: justify;"><span class="sBold">InputBlaster&nbsp;</span><a class="s6" href="#bookmark59">[59]</a>: Valid Input Generator (task 1 and 2) is iterated until it makes the APP transfer (elicited as a single prompt). Task 3 and 4 (also elicited in a single prompt) is also iterated and intermediate results are part of the feedback for effectiveness and diversity. DB is built with buggy examples from GitHUB recorded to match the style used in prompt. Also, unusual inputs that triggered crashes during execution of InputBlaster on the APP. Similarly, it is used to select examples for in-Ctxt Learning.</p>
<p style="text-align: justify;"><span class="sBold">PBT-GPT&nbsp;</span><a class="s6" href="#bookmark88">[88]</a>: Three prompting strategies to generate property-based tests: <em>independently</em> (gen. funct. / property assertion), <em>consecutively</em> (continue conversation after gen. funct.), and <em>together</em> (single big-bang prompt).</p>
</td>
</tr>
<tr>
<td>
<p>Data Set/ Mutant Generation</p>
</td>
<td>
<p><span class="sBold">FSML&nbsp;</span><a class="s6" href="#bookmark6">[6]</a>: line of code &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Line-Mutation⟩</span>&nbsp;&rarr; (mutated line)<span class="s9">+</span> [Few-Shot].</p> 

<p><span class="sBold">MuTAP&nbsp;</span><a class="s6" href="#bookmark16">[16]</a>: prgm under test &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Test-Generation⟩</span>&nbsp;&rarr; initial unit test (incl assert) [Zero-Shot/Few-Shot];</p>
<p style="padding-top: 2pt;">initial unit test + synt errors &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ErrorAware-Test-Correction⟩</span>&nbsp;&rarr; unit test [Zero-Shot/Few-Shot];</p>
<p style="padding-top: 2pt;">prev conv + mutated code &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨AssertionObservable-Differential-Test-Generation⟩</span>&nbsp;&rarr; unit test.</p>
<p><span class="sBold">BugFarm&nbsp;</span><a class="s6" href="#bookmark38">[38]</a>: method signature + method body + statements to transform &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨BugInjecting-Code-Mutation⟩</span>&nbsp;&rarr; transformed code.</p>

<p><span class="sBold">&micro;BERT&nbsp;</span><a class="s6" href="#bookmark47">[47]</a>: masked-code &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Code-Completion⟩</span>&nbsp;&rarr; code<span class="s9">1...5</span> [InFiller]. </p>
<p><span class="sBold">CHEMFUZZ&nbsp;</span><a class="s6" href="#bookmark70">[70]</a>: prev conv + masked-code &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Valid&amp;Diversified-Code-Completion⟩</span>&nbsp;&rarr; code;</p>
<p style="padding-top: 2pt;">exec output &rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Behavior-Anomaly-Detection⟩</span>&nbsp;&rarr; eval report.</p>
<p><span class="sBold">FormAI&nbsp;</span><a class="s6" href="#bookmark84">[84]</a>: type of prgm + style &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨IntentCorresponding-Code-Generation⟩</span>&nbsp;&rarr; prgm.</p>

<p><span class="sBold">LLMorpheus&nbsp;</span><a class="s6" href="#bookmark85">[85]</a>: source code fragment with placeholder + masked orig code &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨DifferentBehavior-Mutation-Generation⟩</span>&nbsp;&rarr; (replacement + brief explanation)<span class="s9">+</span>.</p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">FSML&nbsp;</span><a class="s6" href="#bookmark6">[6]</a>: Study on potential proficiency.</p>
<p style="text-align: justify;"><span class="sBold">MuTAP&nbsp;</span><a class="s6" href="#bookmark16">[16]</a>: LLMs are invoked in a mutant-based test generation approach. </p>
<p style="text-align: justify;"><span class="sBold">BugFarm&nbsp;</span><a class="s6" href="#bookmark38">[38]</a>: LLM is used in the last of the 3 stages that includes method extraction, an a model&rsquo;s attention to different parts of code to identify where to inject bugs.</p>
<p style="text-align: justify;"><span class="sBold">&micro;BERT&nbsp;</span><a class="s6" href="#bookmark47">[47]</a>: Invoked to predict masked token. Stochasticity used to get 5 completions.</p>
<p style="text-align: justify;"><span class="sBold">CHEMFUZZ&nbsp;</span><a class="s6" href="#bookmark70">[70]</a>: LLM integrated into a fuzzing scheme.</p>
<p style="text-align: justify;"><span class="sBold">FormAI&nbsp;</span><a class="s6" href="#bookmark84">[84]</a>: Generation is the first phase for the construction of a labelled data set for vulnerability analysis.</p>
</td>
</tr>
<tr>
<td>
<p>General Fuzzing</p>
</td>
<td>
<p><span class="sBold">OSS-Fuzz&nbsp;</span><a class="s6" href="#bookmark28">[28]</a>: funct to tgt + project specific info &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨DriverCode-Generation⟩</span></p>
<p class="s2" style="padding-left: 6pt; text-indent: 0pt; text-align: left;">&rarr; fuzz driver;</span></p>
<p style="padding-left: 6pt; padding-right: 4pt; text-indent: 0pt; text-align: left;">funct to tgt + project specific info + compilation errors &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ErrorAware-Driver-Code-Correction⟩</span>&nbsp;&rarr; fuzz driver.</span></p>
<p><span class="sBold">ChatFuzz&nbsp;</span><a class="s6" href="#bookmark32">[32]</a>: (sample input)</span><span class="s9">0...1</span> + (format name)</span><span class="s9">0...1</span> &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨File-Variation-Generation⟩</span>&nbsp;&rarr; file [(InFiller)].</span></p>
<p style="padding-left: 6pt; text-indent: 0pt; line-height: 10pt; text-align: left;"><span class="sBold">Fuzz4All&nbsp;</span><a class="s6" href="#bookmark97">[97]</a>: doc + (examp)</span><span class="s4">&lowast;</span> + (specs)</span><span class="s4">&lowast;</span> &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨Usage-Summarization</span><span class="s12" style="background-color: #ecb4cb;">⟩</span><span class="s2"> &rarr;</span> distilled usage/funct;</p>
<p style="padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: left;">usage/funct &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨UsageSastifying-Input-Generation⟩</span>&nbsp;&rarr; fuzz inputs; usage/funct + input &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨SpecificationAware-Input-Mutation⟩</span>&nbsp;&rarr; mutated input; usage/funct + fuzz input &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Input-Variation-Generation⟩</span>&nbsp;&rarr; fuzz input.</span></p>
<p><span class="sBold">UGCTX&nbsp;</span><a class="s6" href="#bookmark105">[105]</a>: header file + API usage examp + funct name &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨DriverCode-Generation⟩</span>&nbsp;&rarr; fuzz driver (UGCTX);</span></p>
<p>fuzz driver code + errors (compilation, link, run-time) + root cause API usage info &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ErrorAware-DriverCode-Correction⟩</span>&nbsp;&rarr; fuzz driver (EX-ITER).</span></p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">OSS-Fuzz&nbsp;</span><a class="s6" href="#bookmark28">[28]</a>: Part of a large project that includes introspection components and fuzzing ones. The description is a best effort from the on-line documentation.</span></p>
<p style="text-align: justify;"><span class="sBold">ChatFuzz&nbsp;</span><a class="s6" href="#bookmark32">[32]</a>: Use stochasticity to generate seeds in grey-box fuzzing workflow.</span></p>
<p style="text-align: justify;"><span class="sBold">Fuzz4All&nbsp;</span><a class="s6" href="#bookmark97">[97]</a>: Autoprompting distill user provided inputs. LLM-powered fuzzing loops which resort to generation, mutation and semantically equiv. variant generation.</span></p>
<p class="sBold" style="padding-left: 5pt; padding-right: 3pt; text-indent: 0pt; text-align: justify;">UGCTX&nbsp;</span><a class="s6" href="#bookmark105">[105]</a>: Study of strategies. The two most sophisticated are reported.</span></p>
</td>
</tr>
<tr style="height: 162pt;">
<td>
<p>Kernel Fuzzing</p>
</td>
<td>
<p class="sBold" style="padding-top: 5pt; padding-left: 6pt; text-indent: 0pt; text-align: justify;">KernelGPT&nbsp;</span><a class="s6" href="#bookmark100">[100]</a>: operation handler code + usage op handl code </span><span class="s2">&rarr;</span></p>
<p style="padding-left: 5pt; padding-right: 5pt; text-indent: 0pt; text-align: justify;"><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">CodeElements-Identification⟩</span>&nbsp;&rarr; device name + initialization op [Few-Shot] (Driver Detection);</span></p>
<p style="padding-left: 6pt; padding-right: 4pt; text-indent: 0pt; line-height: 91%; text-align: justify;">ioctl handl funct + assoc helper funct code + (fetched funct &amp; types + prev inferred usage info) </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">InfoRequesting-CodeElements-Identification⟩</span>&nbsp;&rarr; (command values)</span><span class="s4">&lowast;</span> + (further required [functs,types] + usageInfo) [Few-Shot, Iterative Prompting: functs, types] (Command Value);</span></p>
<p style="padding-left: 5pt; padding-right: 3pt; text-indent: 0pt; text-align: justify;">argument to type + prev detected relevant funct code + argument&rsquo;s usage + (fetched funct code) </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">InfoRequesting-Type-Identification⟩</span>&nbsp;&rarr; argument type</span></p>
<p class="s1" style="padding-left: 5pt; padding-right: 5pt; text-indent: 0pt; text-align: justify;">+ further required (functs) [Few-Shot, Iterative Prompting: functs, types] (Argument Type);</p>
<p>type to describe + src-code structs + (fetched snip) </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">InfoRequesting-Definition-Extraction⟩</span>&nbsp;&rarr; type def + further required (nested type) [Iterative Prompting: nested types] (Type Definition);</span></p>
<p>spec -made up identified elements- + errors &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ErrorAware-Specification-Correction⟩</span>&nbsp;&rarr; spec [Few-Shot] (Specification Validation and Repair).</span></p>
</td>
<td>
<p class="sBold" style="padding-top: 5pt; padding-left: 5pt; padding-right: 3pt; text-indent: 0pt; text-align: justify;">KernelGPT&nbsp;</span><a class="s6" href="#bookmark100">[100]</a>: Syscall specification generation for enhancing fuzzing. A kernel code extractor feeds the LLM with the appropriate code snippets when requested. Refine and repair with feedback provided by external specification validation tool.</span></p>
</td>
</tr>
<tr style="height: 115pt;">
<td>
<p class="s1" style="padding-top: 5pt; padding-left: 6pt; padding-right: 21pt; text-indent: 0pt; text-align: justify;">Compiler/ Simulator Fuzzing</p>
</td>
<td>
<p style="padding-top: 5pt; padding-left: 5pt; text-indent: 0pt; text-align: left;"><span class="sBold">SearchGEM5&nbsp;</span><a class="s6" href="#bookmark15">[15]</a>: code &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ParameterizedVersion-Code-Generation⟩</span>&nbsp;&rarr; param version + type of params [Few-Shot];</span></p>
<p style="padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: left;">parameterized version + types &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Valid-Input-Generation⟩</span>&nbsp;&rarr; input sample [Few-Shot].</span></p>
<p class="sBold" style="padding-left: 5pt; text-indent: 0pt; text-align: left;">WhiteFox&nbsp;</span><a class="s6" href="#bookmark99">[99]</a>: expect input format + optimization name + src-code </span><span class="s2">&rarr;</span></p>
<p><span class="s12" style="background-color: #ecb4cb;">⟨</span><span class="s13" style="background-color: #ecb4cb;">CodeReachability-Input-Characterization</span><span class="s12" style="background-color: #ecb4cb;">⟩ </span><span class="s2"> &rarr; </span>summ trigger input pattern [Few-Shot];</span></p>
<p>expected input format + input pattern &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ConstraintSatisfying-Input-Generation⟩</span>&nbsp;&rarr; summ trigger input pattern [Few-Shot with feedback loop].</span></p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">SearchGEM5&nbsp;</span><a class="s6" href="#bookmark15">[15]</a>: Generates binary inputs for testing an HW-SW architecture simulator. That is, the tool also includes compilation, fuzzing and differential testing. LLM-tasks are elicited by in-chained prompts and a last prompt that requests the parameterized version, sample input and type.</span></p>
<p style="text-align: justify;"><span class="sBold">WhiteFox&nbsp;</span><a class="s6" href="#bookmark99">[99]</a>: Multi-armed bandit algorithm is used to choose few shots for prompts.</span></p>
</td>
</tr>
<tr style="height: 124pt;">
<td>
<p>Protocol/Parser Fuzzing</p>
</td>
<td>
<p><span class="sBold">FuzzingParsers&nbsp;</span><a class="s6" href="#bookmark1">[1]</a>: name object </span><span class="s2">&rarr; </span><span class="s21" style="background-color: #cae6e4;">⟨</span><span class="s22" style="background-color: #cae6e4;">StructureOfObject-Recall</span><span class="s21" style="background-color: #cae6e4;">⟩</span><span class="s2"> &rarr; </span>well-formed tree structure;</span></p>
<p>terminal name + (prev examples) </span><span class="s2">&rarr; </span><span class="s21" style="background-color: #cae6e4;">⟨</span><span class="s22" style="background-color: #cae6e4;">New-ExampleOfThing-Recall</span><span class="s21" style="background-color: #cae6e4;">⟩</span><span class="s2"> &rarr; </span>example;</span></p>
<p>name of parser </span><span class="s2">&rarr; </span><span class="s21" style="background-color: #cae6e4;">⟨</span><span class="s22" style="background-color: #cae6e4;">ParsingErrors-Recall</span><span class="s21" style="background-color: #cae6e4;">⟩</span><span class="s2"> &rarr; </span>described parsing errors;</span></p>
<p>string + error description &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ErrorTriggering-Data-Variation-Generation⟩</span><span class="s2"> &rarr;</span></p>
<p class="s1" style="padding-left: 6pt; text-indent: 0pt; text-align: left;">string;</p>
<p>strings + type &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨Fuse-Transformation-Data⟩</span>&nbsp;&rarr; string.</span></p>
<p style="padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: left;"><span class="sBold">ChatAFL&nbsp;</span><a class="s6" href="#bookmark63">[63]</a>: protocol name </span><span class="s2">&rarr; </span><span class="s21" style="background-color: #cae6e4;">⟨</span><span class="s22" style="background-color: #cae6e4;">ProtocolGrammar-Recall</span><span class="s21" style="background-color: #cae6e4;">⟩</span><span class="s2"> &rarr; </span>msg grammar [Few-Shot: expected format];</span></p>
<p>msg seq + desired additions &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ModificationSpecified-MS-Edition⟩</span>&nbsp;&rarr; msg seq; comm history &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Message-Completion⟩</span>&nbsp;&rarr; msg.</span></p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">FuzzingParsers&nbsp;</span><a class="s6" href="#bookmark1">[1]</a>: These tasks belong to seed generation stage. Other stages include fuzzing and preprocessing.</span></p>
<p class="sBold" style="padding-left: 5pt; padding-right: 5pt; text-indent: 0pt; text-align: justify;">ChatAFL&nbsp;</span><a class="s6" href="#bookmark63">[63]</a>: Multiple conversations with the LLM and majority vote for the final grammar. Interaction with editor to generate new seed. Interaction with completer to get message that would move protocol into a new state.</span></p>
</td>
</tr>
<tr style="height: 105pt;">
<td>
<p class="s1" style="padding-top: 5pt; padding-left: 6pt; padding-right: 10pt; text-indent: 0pt; text-align: left;">DL-Libraries Fuzzing</p>
</td>
<td>
<p class="sBold" style="padding-top: 5pt; padding-left: 5pt; text-indent: 0pt; text-align: left;">TitanFuzz&nbsp;</span><a class="s6" href="#bookmark20">[20]</a>: lib name + DL-API + expec tasks/intent </span><span class="s2">&rarr;</span></p>
<p><span class="s7" style="background-color: #9fd2ec;">⟨</span><span class="s8" style="background-color: #9fd2ec;">IntentCorresponding-Code-Generation⟩</span>&nbsp;&rarr; code;</span></p>
<p style="padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: left;">masked-code &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Code-Completion⟩</span>&nbsp;&rarr; code [Pretrained, InFiller]. </span><span class="sBold">FuzzGPT&nbsp;</span><a class="s6" href="#bookmark21">[21]</a>: code snip </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨APIUsed-Code-MultiClass-Classification⟩</span>&nbsp;&rarr; API label [Few-Shot];</span></p>
<p>name API to be used + code snip &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ModificationSpecified-Code-Edition⟩</span><span class="s2"> &rarr;</span></p>
<p class="s1" style="padding-left: 6pt; text-indent: 0pt; text-align: left;">code snip using API;</p>
<p>API name &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨BugTriggering-Code-Generation⟩</span>&nbsp;&rarr; code [Few-Shot: classif snips, CoT: bug descrip];</span></p>
<p style="padding-left: 5pt; text-indent: 0pt; text-align: left;">API name + prtl code snip &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨BugRevealing-Code-Completion⟩</span>&nbsp;&rarr; code.</span></p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">TitanFuzz&nbsp;</span><a class="s6" href="#bookmark20">[20]</a>: Invoked in an evolutionary workflow to generate seeds and complete mutants.</span></p>
<p style="text-align: justify;"><span class="sBold">FuzzGPT&nbsp;</span><a class="s6" href="#bookmark21">[21]</a>: Data Set (DS) preparation uses Classifier role. Then, random pick from DS and use alternative roles/strategies.</span></p>
</td>
</tr>
<tr style="height: 219pt;">
<td>
<p>GUI Testing</p>
</td>
<td>
<p><span class="sBold">QTypist&nbsp;</span><a class="s6" href="#bookmark57">[57]</a>: input widget type + local ctxt + global ctxt &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Input-Completion⟩</span>&nbsp;&rarr; generated input;</span></p>
<p>masked input + local ctxt + global ctxt &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Input-InFilling⟩</span>&nbsp;&rarr; generated input.</span></p>
<p style="padding-left: 6pt; padding-right: 3pt; text-indent: 0pt; text-align: left;"><span class="sBold">GPTDroid&nbsp;</span><a class="s6" href="#bookmark58">[58]</a>: prev conv + GUI ctxt + prev action fdbk + functionality-aware memory &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨FunctionCoverageOriented-NextAction-Selection⟩</span>&nbsp;&rarr; funct being tested + status + next action [Few-Shot: to define output format]; action + new GUI ctxt + testing memory </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Testing-Status-Analysis⟩</span>&nbsp;&rarr; testing status summary.</span></p>
<p style="padding-left: 5pt; padding-right: 5pt; text-indent: 0pt; line-height: 91%; text-align: justify;"><span class="sBold">AXNav&nbsp;</span><a class="s6" href="#bookmark82">[82]</a>: accessibility test instruct + name of app under test + formatted UI element &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨TestGoalCorresponding-Plan-Generation⟩</span>&nbsp;&rarr; tentative plan = (task, action descr, justification, eval criteria, status)</span><span class="s4">&lowast;</span> [CoT: justification] (planner);</span></p>
<p>UI rep + test instruct &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨Plan-Refinement⟩</span>&nbsp;&rarr; concrete action [CoT: though, relevant UI ids, UI relevant elements] (mapper);</span></p>
<p style="padding-left: 5pt; padding-right: 4pt; text-indent: 0pt; text-align: justify;">test goal + tentative plan + concrete action + assoc thought + UI detections before + UI detections after + eval hints </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨PlannedAction-Successfullness-Assessment⟩</span>&nbsp;&rarr; eval criteria + result + explanation [CoT: eval criteria] (evaluator);</span></p>
<p style="padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: justify;">test goal + tentative plan + current step + (field including a stop cond or eval error) &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨StepOutcomeCorresponding-Plan-Correction⟩</span>&nbsp;&rarr; updated tentative plan (replanner).</span></p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">QTypist&nbsp;</span><a class="s6" href="#bookmark57">[57]</a>: Prompts are generated by a set of rules on context information. Prompt-tuning is also in place.</span></p>
<p class="sBold" style="padding-left: 5pt; padding-right: 3pt; text-indent: 0pt; text-align: justify;">GPTDroid&nbsp;</span><a class="s6" href="#bookmark58">[58]</a>: Tool builds prompts following linguistic patterns instantiated with extracted APP context information. Interaction follows question and answer style, which means in this case that when function being tested and status is yielded by the LLM, another question instructs LLM to yield next action. </span>AXNav&nbsp;</span><a class="s6" href="#bookmark82">[82]</a>: LLM-based UI navigation system to translate from natural language test instructions into a set of concrete steps, execute steps in the plan by calling APIs that interact with a device, and feedback results to the planner when needed.</span></p>
</td>
</tr>
<tr style="height: 228pt;">
<td>
<p>Functional Testing</p>
</td>
<td>
<p style="padding-top: 5pt; padding-left: 6pt; padding-right: 4pt; text-indent: 0pt; text-align: left;"><span class="sBold">TARGET&nbsp;</span><a class="s6" href="#bookmark19">[19]</a>: traffic rule &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨DSLValid&amp;TryToUseGivenElements-RuleConsistent-Scenario-Generation⟩</span>&nbsp;&rarr; draft scenario-rep [Few-Shot] (Know.Extract.); draft scenario-rep + rules &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨RuleInconsistencies-Scenario-Correction⟩</span>&nbsp;&rarr; scenario (Know.Val.);</span></p>
<p style="padding-left: 6pt; padding-right: 3pt; text-indent: 0pt; text-align: left;">subcomponent scenario-rep + list of elements &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨InListCloseMeaning-Elements-Replacement⟩</span>&nbsp;&rarr; scenario (Syntax Alignm.).</span></p>
<p style="padding-left: 5pt; text-indent: 0pt; text-align: left;"><span class="sBold">ScenarioNL&nbsp;</span><a class="s6" href="#bookmark22">[22]</a>: crash incident report &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨Focused-Summarization⟩</span>&nbsp;&rarr; relevant dynamics + static objects [ToT: experts debate];</span></p>
<p style="padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: left;">crash incident report + relevant objects </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Ambiguity-Analysis⟩</span>&nbsp;&rarr; questions to disambiguate;</span></p>
<p style="padding-left: 5pt; padding-right: 4pt; text-indent: 0pt; text-align: left;">crash incident report + question to disambiguate </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨ExpertSolvedUncertainty-TextDependent-QuestionAnswering⟩</span>&nbsp;&rarr; answers [ToT: experts debate]; relevant objects + properties &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ProbabilisticProgram-Generation⟩</span>&nbsp;&rarr; Program (part) [Few-Shot + RAG or HyDE, Function Calling: GPL2DSL].</span></p>
<p><span class="sBold">LLMeDiff&nbsp;</span><a class="s6" href="#bookmark39">[39]</a>: rule &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Pass+Fail+N/A-Test-Generation⟩</span>&nbsp;&rarr; test + confidence.</span></p>
<p><span class="sBold">SysKG-UTF&nbsp;</span><a class="s6" href="#bookmark78">[78]</a>: bug reports </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">StructureCompliant-Information-Extraction</span><span class="s19" style="background-color: #f3d2b7;">⟩</span></p>
<p style="padding-left: 6pt; padding-right: 4pt; text-indent: 0pt; text-align: left;"><span class="s2">&rarr; </span>preconds + steps to reprod (S2R) + obs behav + expect behav [Few-Shot]; S2R &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨StepsToReproduce-Refinement⟩</span>&nbsp;&rarr; (finer grained) S2R [Few-Shot]; bug scenario pair (incl S2R) &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨FeasibilityRedundancyAware-StepsToReproduce-Fusing(edition)⟩</span>&nbsp;&rarr; S2R [Few-Shot, CoT: pseudo-code guided interm assess]; bug scenario pair + potential (fused) S2R &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨FeasibilityAware-StepsToReproduce-Refinement⟩</span>&nbsp;&rarr; S2R [Few-Shot, CoT: assess].</span></p>
</td>
<td>
<p><span class="sBold">TARGET&nbsp;</span><a class="s6" href="#bookmark19">[19]</a>: Takes three phases to parse a traffic rule description to an executable driving scenario in a simulator. LLM addresses first processing phase. </span>
<p><span class="sBold">ScenarioNL&nbsp;</span><a class="s6" href="#bookmark22">[22]</a>: ScenarioNL allows users to specify a model and prompting technique. Scenic database is used to store and retrieve semantically similar examples.</span></p>
<p style="text-align: justify;"><span class="sBold">SysKG-UTF&nbsp;</span><a class="s6" href="#bookmark78">[78]</a>: LLMs play different roles in the construction and post-processing of a knowledge graph for exploratory testing.</span></p>
</td>
</tr>
<tr style="height: 162pt;">
<td>
<p class="s1" style="padding-top: 5pt; padding-left: 5pt; padding-right: 15pt; text-indent: 0pt; text-align: left;">Penetration Testing</p>
</td>
<td>
<p><span class="sBold">PentestGPT&nbsp;</span><a class="s6" href="#bookmark18">[18]</a>: user-intents &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨IntentCorresponding-Plan-Generation</span><span class="s23" style="background-color: #d3bfd7;">⟩</span><span class="s2"> &rarr;</span></p>
<p class="s1" style="padding-left: 6pt; text-indent: 0pt; text-align: left;">penetration task tree (ptt) (1);</p>
<p>testing results + ptt &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨Elements-Update⟩</span>&nbsp;&rarr; ptt (2);</span></p>
<p>ptt + updated ptt </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Validity-Transition-Analysis⟩</span>&nbsp;&rarr; result (3);</span></p>
<p style="padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: left;">ptt &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨RulesSatisfying-Information-Extraction⟩</span>&nbsp;&rarr; (potential next task)</span><span class="s9">+</span> (4); ptt + tasks &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨MostPromising-NextTask-Selection⟩</span>&nbsp;&rarr; sugg next task (5); sub-task + avail tools &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨ToolsConstrained-Plan-Generation⟩</span>&nbsp;&rarr; seq of steps [CoT] (6);</span></p>
<p>step &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨Plan-Refinement⟩</span>&nbsp;&rarr; cmd [CoT] (7);</span></p>
<p style="padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: left;">raw user intent &mdash; test outp &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨Summarization⟩</span>&nbsp;&rarr; condensed info (8). </span><span class="sBold">pwn&rsquo;d&nbsp;</span><a class="s6" href="#bookmark30">[30]</a>: scenario &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨ScenarioCorresponding-Plan-Generation⟩</span>&nbsp;&rarr; pen-test plan [Agent GPT];</span></p>
<p>goal + prev conv + last cmd output &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨ReachabilityOriented-NextAction-</span> <span class="s24" style="background-color: #d3bfd7;">Generation⟩</span>&nbsp;&rarr; cmd;</span></p>
<p style="padding-left: 6pt; padding-right: 4pt; text-indent: 0pt; text-align: left;">cmd + output </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-VulnerabilityProneness-CommandExecution-Mul-</span> <span class="s18" style="background-color: #d6df8c;">tiLabel-Classification⟩</span>&nbsp;&rarr; potential vul.</span></p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">PentestGPT&nbsp;</span><a class="s6" href="#bookmark18">[18]</a>: It incorporates three core modules: the Reasoning Module (1&ndash;5), the Generation Module (6,7), and the Parsing Module (8) (each reserving an LLM session). Active user feedback is possible.</span></p>
<p style="text-align: justify;"><span class="sBold">pwn&rsquo;d&nbsp;</span><a class="s6" href="#bookmark30">[30]</a>: High-level task planning uses mechanisms to integrate LLMs as agents (AutoGPT). Low-level vector attack works as a step by step reactive execution of plan.</span></p>
</td>
</tr>
<tr style="height: 17pt;">
<td>
<p>Oracle Problem</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
</td>
<td>
<p style="padding-top: 5pt; padding-left: 6pt; text-indent: 0pt; line-height: 9pt; text-align: left;"><span class="sBold">FSML&nbsp;</span><a class="s6" href="#bookmark6">[6]</a>: sig + meth-intent &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨MetamorphicAssertion-Characterization</span><span class="s12" style="background-color: #ecb4cb;">⟩</span><span class="s2"> &rarr;</span></p>
<p>term-equiv assertions [Few-Shot, CoT: </span><span class="s25" style="background-color: #ecb4cb;">code intent</span> + analysis].</span></p>
<p><span class="sBold">SELF-DEBUGGING&nbsp;</span><a class="s6" href="#bookmark12">[12]</a>: sql-query &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨SQL-CodeCorresponding-Explana-</span></p>
<p><span class="s13" style="background-color: #ecb4cb;">tion-Generation⟩</span>&nbsp;&rarr; explanation [Few-Shot];</span></p>
<p>sql-query &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨QueryConsistent-TableResult-Generation⟩</span>&nbsp;&rarr; result table [Few-</span> Shot];</p>
<p>sql-query + result table &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨SQL-Code&amp;ExecutionCorresponding-Explanation-</span></p>
<p><span class="s13" style="background-color: #ecb4cb;">Generation⟩</span>&nbsp;&rarr; explanation [Few-Shot];</span></p>
<p>explanation &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨ColumnOriented-Explanation-Summarization</span><span class="s12" style="background-color: #ecb4cb;">⟩ </span><span class="s2">&rarr; </span>column-intents</span> [Few-Shot];</p>
<p>NL query &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨Rationalized-NLQuery-NumberOfColumns-Identification⟩</span>&nbsp;&rarr; NL-</span>query columns [Few-shot,CoT];</p>
<p>NL-query columns + column-intents </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Docstrings-Equivalence-Checking</span><span class="s16" style="background-color: #d6df8c;">⟩</span><span class="s2"> &rarr;&nbsp;</span>feedback [Few-Shot] (Correctness TEXT-TO-SQL); intent + assertion + code + (external feedback) + code explanation <span class="s2">&rarr;</span></p>
<p><span class="s16" style="background-color: #d6df8c;">⟨</span><span class="s18" style="background-color: #d6df8c;">Intent&amp;AssertionCorresponding-Code-OneClass-Classification⟩</span>&nbsp;&rarr; yes/no [Few-</span></p>
<p>Shot, CoT: </span><span class="s25" style="background-color: #d3bfd7;">assertion execution</span>] (Correctness TEXT-TO-PYTHON).</span></p>
<p><span class="sBold">nl2postcondition&nbsp;</span><a class="s6" href="#bookmark23">[23]</a>: intent + (refer impl)</span><span class="s9">0...1</span> &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨PostCondition-</span></p>
<p><span class="s13" style="background-color: #ecb4cb;">Formalization⟩</span>&nbsp;&rarr; assertions.</span></p>
<p><span class="sBold">TOGLL&nbsp;</span><a class="s6" href="#bookmark31">[31]</a>: test prefix + MUT code + MUT doc &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Assertion-Generation⟩</span></p>
<p class="s2" style="padding-left: 6pt; text-indent: 0pt; line-height: 8pt; text-align: left;">&rarr; assertion.</span></p>
<p><span class="sBold">Eywa&nbsp;</span><a class="s6" href="#bookmark42">[42]</a>: funct defs + arguments + result + validity constraints </span>&rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ProtocolModelImplementation-Generation⟩</span>&nbsp;&rarr; model code.</span></p>
<p><span class="sBold">PropertyGPT&nbsp;</span><a class="s6" href="#bookmark56">[56]</a>: base rule code + funct code under test + contract</span></p>
<p>src-code &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Similar-Assertion-Generation⟩</span>&nbsp;&rarr; rule code [RAG: base rule code];</span></p>
<p>base pre/post + funct under test &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Similar-Assertion-Generation⟩</span>&nbsp;&rarr; funct-</span> level pre/post [RAG: base pre/post]; rule code + contract src-code + error info + funct under test name <span class="s2">&rarr;</span></p>
<p><span class="s7" style="background-color: #9fd2ec;">⟨</span><span class="s8" style="background-color: #9fd2ec;">ErrorAware-Assertion-Correction⟩</span>&nbsp;&rarr; rule code;</span> rule code + contract src-code + base rule code + missing funct under test</p>
<p>name &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨MissingFunction-Assertion-Correction⟩</span>&nbsp;&rarr; rule code.</span></p>
<p><span class="sBold">ClarifyGPT&nbsp;</span><a class="s6" href="#bookmark66">[66]</a>: MUT sig + doc &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨IntentCorresponding-Code-Generation⟩</span> <span class="s2">&rarr; </span>(code)<span class="s4">&lowast;</span>;</p>
<p>MUT sig + doc &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Basic&amp;Edge-TestInput-Generation⟩</span>&nbsp;&rarr; (test)</span><span class="s9">+</span> [Few-Shot];</span></p>
<p>req + (code of alt sol)</span><span class="s9">+</span> &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨CodeDifferences-Verbalization⟩</span>&nbsp;&rarr; descr and diffs</span> [Few-Shot];</p>
<p>req + alt sol descr and diffs </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Ambiguity-Analysis⟩</span>&nbsp;&rarr; clarifying questions</span> [Few-Shot].</p>
<p><span class="sBold">CEDAR&nbsp;</span><a class="s6" href="#bookmark67">[67]</a>: focal meth + unit-test snip &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Assertion-Generation⟩</span>&nbsp;&rarr; assert</span> [Few-Shot + RAG: retrv demo (U-Test snip)].</p>
<p><span class="sBold">PROSPER&nbsp;</span><a class="s6" href="#bookmark74">[74]</a>: RFC doc. </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">FSM-Elements-Extraction⟩</span>&nbsp;&rarr; FSM-elements</span> [Few-Shot].</p>
<p><span class="sBold">EMR&nbsp;</span><a class="s6" href="#bookmark76">[76]</a>: req doc </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">IORelated-Sentences-Identification⟩</span>&nbsp;&rarr; I/O sentences;</span></p>
<p>I/O sentences &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨SentenceDerivable-MethamorpicRelation-Characterization⟩</span>&nbsp;&rarr; metamorphic relation (MR);</p>
<p>MR + SUT API + SUT docum &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨RequirementsDerivable-ExecutionMethamor-</span></p>
<p><span class="s8" style="background-color: #9fd2ec;">picRelations-Generation⟩</span>&nbsp;&rarr; executable metamorphic relations [Few-Shot:&nbsp;</span>DSL].</p>
<p><span class="sBold">GameBugDescriptions&nbsp;</span><a class="s6" href="#bookmark83">[83]</a>: video game name + scenario + perspective</span></p>
<p>(e.g. game designer, player, real-world) </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Scenario-AccordingToPerspective-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">Anomaly-Detection⟩</span>&nbsp;&rarr; thought;</span></p>
<p>prev conv &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨Answer-FailureOriented-Summarization</span><span class="s12" style="background-color: #ecb4cb;">⟩ </span><span class="s2"> &rarr; </span>buggy event (Answer</span> Extraction).</p>
<p><span class="sBold">MetaMorph&nbsp;</span><a class="s6" href="#bookmark86">[86]</a>: doc snip </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">VariableNames-Identification⟩</span>&nbsp;&rarr; vars [Few-</span> Shot].</p>
<p><span class="sBold">ALGO&nbsp;</span><a class="s6" href="#bookmark108">[108]</a>: prob formul + in/out examp &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨BruteForce-IntentCorrespond-</span></p>
<p><span class="s8" style="background-color: #9fd2ec;">ing-Code-Generation⟩</span>&nbsp;&rarr; implem.</span></p>
</td>
<td>
<p><span class="sBold">FSML&nbsp;</span><a class="s6" href="#bookmark6">[6]</a>: Study on potential profi</span>ciency.</p>
<p><span class="sBold">SELF-DEBUGGING&nbsp;</span><a class="s6" href="#bookmark12">[12]</a>: For the</span> Generation step, given the problem description, the model predicts candidate programs (not shown in this report). Explanation step, the model is prompted to process the predictions in a &ldquo;semantically useful way&rdquo;, such as explaining the prediction (and reference NL query for SQL query generation, source program for translation program) in natural language. Correctness is then predicted by different tasks depending on the code generation/translation problem. Here</p>
<p class="s1" style="padding-left: 5pt; text-indent: 0pt; line-height: 9pt; text-align: left;">we show how this can be determined by asking the model itself to work as oracle of correctness. Generation, explanation, evaluation and repair are chained in demonstrations.</p>
<p><span class="sBold">TOGLL&nbsp;</span><a class="s6" href="#bookmark31">[31]</a>: Six different prompts are studied. We report one with the richest context (P6).</span></p>
<p><span class="sBold">Eywa&nbsp;</span><a class="s6" href="#bookmark42">[42]</a>: LLM is used to generate protocol model code. Symbolic execution is further used to generate test cases.-</span> </p>
<p><span class="sBold">PropertyGPT&nbsp;</span><a class="s6" href="#bookmark56">[56]</a>: Uses Retrieval augmented generation by providing relevant specifications to be based on.</span></p>
<p><span class="sBold">ClarifyGPT&nbsp;</span><a class="s6" href="#bookmark66">[66]</a>: Intention clarification is part of this code generation approach. Generated inputs (and mutations) are used to cluster solutions. Differences analysis and clarifying questions are actually performed by a single prompt.</span></p>
<p><span class="sBold">CEDAR&nbsp;</span><a class="s6" href="#bookmark67">[67]</a>: General demonstration retrieval method illustrated in assertion generation. Neural and frequency-based techniques for retrieval.</span></p>
<p><span class="sBold">EMR&nbsp;</span><a class="s6" href="#bookmark76">[76]</a>: Initial study on generating metamorphic relations from documentation and executable metamorphic relations. Some details on prompt engineering are not provided and are conjectural.</span> </p>
<p><span class="sBold">ALGO&nbsp;</span><a class="s6" href="#bookmark108">[108]</a>: This (oracle synthesis) is part of a program generation framework. Program generation may use implicit or explicit search (e.g., algorithmic ideas).</span></p>
</td>
</tr>
</tbody>
</table>
<p style="padding-top: 1pt; text-indent: 0pt; text-align: left;">&nbsp;</p>
<p style="padding-left: 8pt; text-indent: 0pt; text-align: left; font-size: 12pt;"><b>Table 2:</b> SE task: Debugging.</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
<table style="border-collapse: collapse; margin-left: 6.25pt; border-style: solid;" cellspacing="0">
<tbody>
<tr style="height: 30pt;">
<td style="width: 99pt; border-width: 1pt; border-style: solid;" bgcolor="#B1CECE">
<p>SE Problem</p>
</td>
<td style="width: 520pt; border-width: 1pt; border-style: solid;" bgcolor="#B1CECE">
<p>LLM Downstream Tasks<br>(input</span>&rarr; ⟨<span class="s3">type of task </span>⟩ &rarr;output[learn. strat.])</span><span class="s4">&lowast;</span></p>
</td>
<td style="width: 320pt; border-width: 1pt; border-style: solid;" bgcolor="#B1CECE">
<p>Architectural Notes</p>
</td>
</tr>
<tr style="height: 134pt;">
<td>
<p>Bug Reproduction</p>
</td>
<td>
<p><span class="sBold">AdbGPT&nbsp;</span><a class="s6" href="#bookmark24">[24]</a>: bug report </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">StepsToReproduce-Extraction⟩</span>&nbsp;&rarr; steps to reprod [Few-Shot, CoT];</span></p>
<p>view hierarchy of the GUI + step &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨Plan-Refinement⟩</span>&nbsp;&rarr; component to operate [Few-Shot, CoT].</span></p>
<p class="sBold" style="padding-left: 6pt; text-indent: 0pt; text-align: left;">CrashTranslator&nbsp;</span><a class="s6" href="#bookmark37">[37]</a>: manifested page names + curr page + crash page</span></p>
<p style="padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: left;"><span class="s2">&rarr; </span><span class="s23" style="background-color: #d3bfd7;">⟨</span><span class="s24" style="background-color: #d3bfd7;">ReachabilityOriented-NextNode-Selection⟩</span>&nbsp;&rarr; next page [Zero-Shot, LLM fine-tuned with APPs transition relations];</span></p>
<p style="padding-left: 5pt; text-indent: 0pt; text-align: left;">manifested page names + current page + crash page + next page + interactible widgets &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨ReachabilityOrientedWithSuggestedNextNode-NextAction-Selection⟩</span>&nbsp;&rarr; widget [Zero-Shot, LLM fine-tuned with targeted GUI page and transfer widget].</span></p>
<p><span class="sBold">LIBRO&nbsp;</span><a class="s6" href="#bookmark46">[46]</a>: bug report + (stack trace)</span><span class="s9">0...1</span> &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨BugReproducing-Test-</span> <span class="s8" style="background-color: #9fd2ec;">Generation⟩</span>&nbsp;&rarr; test meth [Few-Shot].</span></p>
</td>
<td>
<p class="s1" style="padding-top: 5pt; padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: left;"><a class="s6" href="#bookmark24">AdbGPT&nbsp;</a>[24]: In-chained approach. <span class="sBold">CrashTranslator&nbsp;</span><a class="s6" href="#bookmark37">[</a>37]: It leverages LLM for one of the scorer which goal is to propose exploration priority.</p>
<p style="text-align: justify;"><span class="sBold">LIBRO&nbsp;</span><a class="s6" href="#bookmark46">[46]</a>: LLM works as first component of tool chain. A set of test candidates are generated by querying the LLM multiple times.</span></p>
</td>
</tr>
<tr style="height: 39pt;">
<td>
<p class="s1" style="padding-top: 5pt; padding-left: 5pt; padding-right: 15pt; text-indent: 0pt; text-align: left;">Bug Report Analysis</p>
</td>
<td>
<p><span class="sBold">Cupid&nbsp;</span><a class="s6" href="#bookmark109">[109]</a>: bug report </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">AimedAtDuplicateDetection-Keywords-Extraction</span><span class="s19" style="background-color: #f3d2b7;">⟩</span></p>
<p class="s2" style="padding-left: 6pt; text-indent: 0pt; text-align: left;">&rarr; keywords.</span></p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">Cupid&nbsp;</span><a class="s6" href="#bookmark109">[109]</a>: LLM plays a punctual role into a traditional solution for duplicate bug report.</span></p>
</td>
</tr>
<tr style="height: 210pt;">
<td>
<p>Fault Localization</p>
</td>
<td>
<p class="sBold" style="padding-top: 5pt; padding-left: 6pt; text-indent: 0pt; text-align: justify;">SELF-DEBUGGING&nbsp;</span><a class="s6" href="#bookmark12">[12]</a>: code snippet + code snippet + input + feedback</span></p>
<p>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Differences-RootCause-Analysis⟩</span>&nbsp;&rarr; execution-based analysis [Few-Shot, CoT: </span><span class="s25" style="background-color: #d3bfd7;">trace execution</span>] (C++-TO-PYTHON).</span></p>
<p><span class="sBold">AutoFL&nbsp;</span><a class="s6" href="#bookmark44">[44]</a>: failing test info </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨RootCause-Analysis⟩</span>&nbsp;&rarr; root cause [ReAct: funct calls for debugging];</span></p>
<p style="padding-left: 6pt; text-indent: 0pt; line-height: 9pt; text-align: justify;">prev conv &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨Answer-FaultOriented-Summarization⟩</span>&nbsp;&rarr; culprit.</span></p>
<p><span class="sBold">AutoSD&nbsp;</span><a class="s6" href="#bookmark45">[45]</a>: funct meth + tests + err msg + (reports)</span><span class="s9">0...1 &rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨RootCause-</span> <span class="s18" style="background-color: #d6df8c;">Analysis⟩</span>&nbsp;&rarr; hypoth + prediction + experiment;</span></p>
<p>hypoth + predict + experiment + exp observation </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨EvidenceSupport-</span> <span class="s18" style="background-color: #d6df8c;">Judgment⟩</span>&nbsp;&rarr; conclusion;</span></p>
<p>prev conv &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨DebuggingAware-Code-Generation⟩</span>&nbsp;&rarr; fixed code.</span></p>
<p><span class="sBold">LLM4CBI&nbsp;</span><a class="s6" href="#bookmark87">[87]</a>: prgm + mutation instr + validity fdbk &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨MutationSpecified-</span> <span class="s8" style="background-color: #9fd2ec;">Code-Mutation⟩</span>&nbsp;&rarr; prgm.</span></p>
<p><span class="sBold">ChatGPT-4(Log)&nbsp;</span><a class="s6" href="#bookmark96">[96]</a>: focal source faulty code </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨FaultProneness-Code-</span> <span class="s18" style="background-color: #d6df8c;">Lines-Ranking⟩</span>&nbsp;&rarr; ordered list of lines and reason [CoT: </span><span class="s25" style="background-color: #ecb4cb;">funct intent</span>, reason per line];</span></p>
<p>prev conv + test case + error </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨TestResultAware-FaultProneness-CodeLines-</span> <span class="s18" style="background-color: #d6df8c;">ReRanking⟩</span>&nbsp;&rarr; intent + ordered list of lines and reason.</span></p>
</td>
<td>
<p class="sBold" style="padding-top: 5pt; padding-left: 6pt; text-indent: 0pt; text-align: justify;">SELF-DEBUGGING&nbsp;</span><a class="s6" href="#bookmark12">[12]</a>: For the</span></p>
<p class="s1" style="padding-left: 5pt; padding-right: 3pt; text-indent: 0pt; text-align: justify;">Generation step, given the problem description, the model predicts candidate programs (not shown in this report). The fault detection is performed by creating an execution trace of the predicted code for a sample input.</p>
<p style="text-align: justify;"><span class="sBold">AutoFL&nbsp;</span><a class="s6" href="#bookmark44">[44]</a>: Two stages: root cause explanation and bug location. LLM uses function calling.</span></p>
<p style="text-align: justify;"><span class="sBold">AutoSD&nbsp;</span><a class="s6" href="#bookmark45">[45]</a>: Chained interaction of LLMs with executing engines.</span></p>
<p style="text-align: justify;"><span class="sBold">LLM4CBI&nbsp;</span><a class="s6" href="#bookmark87">[87]</a>: Generation of prompts uses ad-hoc static analysis. Then they are selected, executed and modified in a RL workflow that includes some classic localization techniques.</span></p>
<p style="text-align: justify;"><span class="sBold">ChatGPT-4(Log)&nbsp;</span><a class="s6" href="#bookmark96">[96]</a>: Empirical study of LLMs proficiency. Code context is modified in the controlled experiment to assess impact.</span></p>
</td>
</tr>
<tr style="height: 276pt;">
<td>
<p class="s1" style="padding-top: 5pt; padding-left: 5pt; padding-right: 16pt; text-indent: 0pt; text-align: left;">Root Cause Analysis</p>
</td>
<td>
<p><span class="sBold">RCACopilot&nbsp;</span><a class="s6" href="#bookmark13">[13]</a>: diagnostic info &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨RootCauseOriented-Summarization</span><span class="s12" style="background-color: #ecb4cb;">⟩</span><span class="s2"> &rarr;</span></p>
<p class="s1" style="padding-left: 6pt; text-indent: 0pt; text-align: justify;">summ diag (incident summarization);</p>
<p>incident summ + list close categorized historic incidents </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">Common-Root-</span> <span class="s18" style="background-color: #f3d2b7;">Cause-Selection⟩</span>&nbsp;&rarr; root cause + category [CoT: explanation].</span></p>
<p><span class="sBold">x-lifecycle&nbsp;</span><a class="s6" href="#bookmark27">[27]</a>: service descr &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨RootCauseOriented-Summarization</span><span class="s12" style="background-color: #ecb4cb;">⟩ </span><span class="s2">&rarr; </span>summ svc descr;</span></p>
<p>title incident + summ inc + svc dependencies + svc summ descr + similar historic inc </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨SimilarityGuided-RootCause-Analysis⟩</span>&nbsp;&rarr; root cause + svc dep? </span><span class="sBold">RCAAgents&nbsp;</span><a class="s6" href="#bookmark71">[71]</a>: initial incident info </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨RootCause-Analysis⟩</span>&nbsp;&rarr; root cause [ReAct: rqst for details, rqst for historical inc, query on retrieved inc];</span></p>
<p>retrv text + query </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨TextDependent-QuestionAnswering⟩</span>&nbsp;&rarr; answer.</span></p>
<p style="padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: justify;"><span class="sBold">LM-PACE&nbsp;</span><a class="s6" href="#bookmark107">[107]</a>: (incident, root cause)</span><span class="s9">+</span> + curr incident + (guessed root cause) </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨SufficiencyToInferAnswer-Assessment⟩</span>&nbsp;&rarr; analysis;</span></p>
<p>prev conv &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨Assessment-Yes/No-Summarization⟩</span>&nbsp;&rarr; yes/no (1);</span></p>
<p>relevant-incids with root causes + curr incid + answ root cause </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Answer-</span> <span class="s18" style="background-color: #d6df8c;">Qlty(Truth, Ground, Informative)-Assessment⟩</span>&nbsp;&rarr; analysis;</span></p>
<p>prev conv &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨Assessment-Scaled-Summarization⟩</span>&nbsp;&rarr; score (2). </span><span class="sBold">inContextRCA&nbsp;</span><a class="s6" href="#bookmark110">[110]</a>: report &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨RootCauseOriented-Summarization⟩</span>&nbsp;&rarr; incident + root cause;</span></p>
<p style="padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: justify;">incident report </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨RootCause-Analysis⟩</span>&nbsp;&rarr; root cause [Few-Shot: similar examples].</span></p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">RCACopilot&nbsp;</span><a class="s6" href="#bookmark13">[13]</a>: Diagnostic information collection stage is performed before prediction. Tasks are core part of larger solution.</span></p>
<p style="text-align: justify;"><span class="sBold">x-lifecycle&nbsp;</span><a class="s6" href="#bookmark27">[27]</a>: Vector data base is used for Retrieval Augmented Generation.</span></p>
<p style="text-align: justify;"><span class="sBold">RCAAgents&nbsp;</span><a class="s6" href="#bookmark71">[71]</a>: Vector data base to search for historical incidents.</span></p>
<p style="text-align: justify;"><span class="sBold">LM-PACE&nbsp;</span><a class="s6" href="#bookmark107">[107]</a>: Focus on confidence estimation and calibration. Root cause generation is a black box that can be addressed by LLMs as well. Relevant incidents came from historical-DB (semantic similarity-based retriever). Confidence of Evaluation (COE-score) and Root-Cause-Evaluation (RCE-score) are obtained from (1) and (2) resp. multiple sampling on LLMs. COE and RCE scores are the input of an optimization procedure to build a model to predict calibrated confidence score. In deployment phase, predicted root cause and calibrated confidence score is yield to on-call engineers.</span></p>
<p class="sBold" style="padding-top: 1pt; padding-left: 6pt; padding-right: 4pt; text-indent: 0pt; text-align: justify;">inContextRCA&nbsp;</span><a class="s6" href="#bookmark110">[110]</a>: Vector data base is populated with summarized incidents and root causes.</span></p>
</td>
</tr>
</tbody>
</table>
<p style="padding-top: 2pt; text-indent: 0pt; text-align: left;">&nbsp;</p>
<p style="padding-left: 8pt; text-indent: 0pt; text-align: left; font-size: 12pt;"><b>Table 3:</b> SE task: Vulnerability/Misuse/Malware/Fault Detection.</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
<table style="border-collapse: collapse; margin-left: 6.25pt;" cellspacing="0">
<tbody>
<tr style="height: 30pt;">
<td style="width: 99pt; border-width: 1pt; border-style: solid;" bgcolor="#CEE0C1">
<p>SE Problem</p>
</td>
<td style="width: 520pt; border-width: 1pt; border-style: solid;" bgcolor="#CEE0C1">
<p>LLM Downstream Tasks<br>(input</span>&rarr; ⟨<span class="s3">type of task </span>⟩ &rarr;output[learn. strat.])</span><span class="s4">&lowast;</span></p>
</td>
<td style="width: 320pt; border-width: 1pt; border-style: solid;" bgcolor="#CEE0C1">
<p>Architectural Notes</p>
</td>
</tr>
<tr style="height: 17pt;">
<td>
<p class="s1" style="padding-top: 5pt; padding-left: 5pt; text-indent: 0pt; line-height: 9pt; text-align: left;">Vulnerability Detection</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
</td>
<td>
<p style="padding-top: 5pt; padding-left: 6pt; text-indent: 0pt; line-height: 9pt; text-align: left;"><span class="sBold">ChatGPT4vul&nbsp;</span><a class="s6" href="#bookmark25">[25]</a>: src-code </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨VulnerabilityProneness-Code-OneClass-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">Classification⟩</span>&nbsp;&rarr; yes/no;</span></p>
<p>prev conv </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨VulnerabilityProneness-CodeLines-Ranking⟩</span>&nbsp;&rarr; list;</span></p>
<p>src-code + (tgt CWD-ID)</span><span class="s9">+ &rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨ListTargeted-CWEVulnerabilityProneness-Code-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">MultiLabel-Classification⟩</span>&nbsp;&rarr; CWD-ID;</span></p>
<p>src-code </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨CVSS-Scoring⟩</span>&nbsp;&rarr; score.</span></p>
<p><span class="sBold">VulBench&nbsp;</span><a class="s6" href="#bookmark26">[26]</a>: snip + (vul classes)</span><span class="s9">0...1 &rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-ListTargeted-CWE-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">VulnerabilityProneness-Code-MultiLabel-Classification⟩</span>&nbsp;&rarr; vul verdict + (vul</span> class)<span class="s9">0...1</span> + step by step explanation [Few-Shot: <span class="s2">&isin;</span>project &mdash; <span class="s2">&isin;̸</span>project, CoT].</p>
<p><span class="sBold">NLBSE24&nbsp;</span><a class="s6" href="#bookmark41">[41]</a>: code snippet </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨VulnerabilityProneness-Code-OneClass-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">Classification⟩</span>&nbsp;&rarr; yes/no;</span></p>
<p>code snippet + intended functionality </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨GivenIntentionCorrespondence-Code-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">OneClass-Classification⟩</span>&nbsp;&rarr; yes/no.</span></p>
<p><span class="sBold">VulDetect&nbsp;</span><a class="s6" href="#bookmark48">[48]</a>: tgt code snippet </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-CWEVulnerabilityProne-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">ness-Code-MultiLabel-Classification⟩</span>&nbsp;&rarr; yes/no + vul type + vul name +</span> explanation;</p>
<p>tgt code snip + tgt CWE </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-ListTargeted-CWEVulnerabilityProne-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">ness-Code-MultiLabel-Classification⟩</span>&nbsp;&rarr; yes/no + vul type + vul name +</span> explanation;</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
<p>tgt code snip + CWE-DF </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-DataFlowTargeted-CWEVulnerabil</span><span class="s15">i-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">tyProneness-Code-MultiLabel-Classification⟩</span>&nbsp;&rarr; yes/no + vul type + vul name</span></p>
<p class="s1" style="padding-left: 4pt; text-indent: 0pt; line-height: 8pt; text-align: left;">+ data-flow explanation;</p>
<p>query + data-flow-analysis </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Answer-Quality-Assessment⟩</span>&nbsp;&rarr; yes/no + ex-</span> planation + final verdict.</p>
<p><span class="sBold">GRACE&nbsp;</span><a class="s6" href="#bookmark60">[60]</a>: code snippet + code property graph </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨CPGEnhanced-Vulner-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">abilityProneness-Code-OneClass-Classification⟩</span>&nbsp;&rarr; yes/no [Few-Shot: retrieved</span> demonstration].</p>
<p><span class="sBold">VSP&nbsp;</span><a class="s6" href="#bookmark68">[68]</a>: src-code </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-CWEVulnerabilityProneness-Code-MultiL-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">abel-Classification⟩</span>&nbsp;&rarr; list CWEs [Few-Shot, CoT];</span></p>
<p>src-code + CWE id </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-IdTargeted-CWEVulnerabilityProneness-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">Code-OneClass-Classification⟩</span>&nbsp;&rarr; yes/no + reason [Few-Shot, CoT].</span></p>
<p><a class="s6" href="#bookmark75">AIagent&nbsp;</a>[75]: (vul type name + caveat)</span><span class="s9">+</span> + src-code </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨ListTargeted-CWE-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">VulnerabilityProneness-CodeLine-MultiClass-Classification⟩</span>&nbsp;&rarr; result (category</span></p>
<p class="s1" style="padding-left: 4pt; text-indent: 0pt; line-height: 8pt; text-align: left;">+ line). <span class="sBold">DLAP&nbsp;</span><a class="s6" href="#bookmark101">[</a>101]: code-snippet + (snippet + label + probability)<span class="s9">+</span> <span class="s2">&rarr;</span></p>
<p><span class="s16" style="background-color: #d6df8c;">⟨</span><span class="s18" style="background-color: #d6df8c;">GivenExamples-VulnerabilityProneness-Code-MultiLabel-Soft-Classification</span><span class="s16" style="background-color: #d6df8c;">⟩</span><span class="s2"> &rarr;</span> label + prediction (Super ICL);</p>
<p>guidance steps + code to review + potential vulnerability &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨Plan-Refinement⟩</span>&nbsp;&rarr; specific review-steps (Bespoke CoT Guidance);</span></p>
<p>code + prob prediction + specific review-steps </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-Re-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">viewStepsEnhanced-IdTargeted-CWEVulnerabilityProneness-Code-OneClass-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">Soft-Classification⟩</span>&nbsp;&rarr; vulnerability+prob+reason [CoT: reason] (Final</span> Prompt).</p>
<p><span class="sBold">MultiTask&nbsp;</span><a class="s6" href="#bookmark103">[103]</a>: code snippet </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨VulnerabilityProneness-Code-OneClass-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">Classification⟩</span>&nbsp;&rarr; yes/no (Detection);</span></p>
<p>code snippet </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨CVSS-Scoring⟩</span>&nbsp;&rarr; score (Assessment);</span></p>
<p>code snippet </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨VulnerabilityProneness-CodeLine-OneClass-Classification</span><span class="s16" style="background-color: #d6df8c;">⟩</span><span class="s2"> &rarr;</span> lines (Location);</p>
<p>code snippet </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨CWE-VulnerabilityProneness-Code-MultiLabel-Classification</span><span class="s16" style="background-color: #d6df8c;">⟩</span> <span class="s2">&rarr; </span>(CWE + description)<span class="s4">&lowast;</span> (Description).</p>
<p><span class="sBold">PromptEnhanced&nbsp;</span><a class="s6" href="#bookmark106">[106]</a>: src-code &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨CodeCorresponding-Intent-</span></p>
<p><span class="s13" style="background-color: #ecb4cb;">Verbalization⟩</span>&nbsp;&rarr; intent;</span> src-code + intent + (API call seq) + (data-flow descr) <span class="s2">&rarr;</span></p>
<p><span class="s16" style="background-color: #d6df8c;">⟨</span><span class="s18" style="background-color: #d6df8c;">(APICalls)/(DataFlow)Enhanced-VulnerabilityProneness-Code-OneClass-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">Classification⟩</span>&nbsp;&rarr; yes/no.</span></p>
<p><span class="sBold">ChatGPT(Plus)&nbsp;</span><a class="s6" href="#bookmark112">[112]</a>: project info + ext src knowl (top CWE) + src-code</span></p>
<p>to analyze </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨(CWE+GivenVulnDescr)VulnerabilityPronenes</span><span class="s15">s</span><span class="s18" style="background-color: #d6df8c;">-Code-OneClass-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">Classification⟩</span>&nbsp;&rarr; yes/no [Few-Shot: K-examp either (random)/Few-Shot +</span> AG: simil code to analyze].</p>
</td>
<td>
<p><span class="sBold">ChatGPT4vul&nbsp;</span><a class="s6" href="#bookmark25">[25]</a>: Study of profi-</span> ciency. It includes repair prompts (not reported here).</p>
<p><span class="sBold">VulBench&nbsp;</span><a class="s6" href="#bookmark26">[26]</a>: Study including alter-</span> native prompting strategies.</p>
<p><span class="sBold">NLBSE24&nbsp;</span><a class="s6" href="#bookmark41">[41]</a>: This evaluation also in-</span> cludes tasks versions that take previous labels as inputs.</p>
<p><span class="sBold">VulDetect&nbsp;</span><a class="s6" href="#bookmark48">[48]</a>: Study including al</span>ternative prompting strategies. Self-reflection is one option.</p>
<p><span class="sBold">GRACE&nbsp;</span><a class="s6" href="#bookmark60">[60]</a>: We report the enhanced</span></p>
<p class="s1" style="padding-left: 5pt; text-indent: 0pt; line-height: 8pt; text-align: left;">vulnerability detection module. The approach also consist in a demonstration selection module and a graph structure information generation module.</p>
<p><span class="sBold">AIagent&nbsp;</span><a class="s6" href="#bookmark75">[75]</a>: Preliminary study. Basic</span> prompt is augmented with caveats on each category.</p>
<p><span class="sBold">DLAP&nbsp;</span><a class="s6" href="#bookmark101">[101]</a>: DL models are used to</span> generate a prediction probability that serve as reference input for LLM assessment. LHS is used to find similar code. Static analysis results are key to query to obtain customized CoT generation guidance templates.</p>
<p><span class="sBold">PromptEnhanced&nbsp;</span><a class="s6" href="#bookmark106">[106]</a>: Study on</span> different prompting strategies. It actually tries unsuccessfully to generate data-flow and API calls by using LLM too (property characterization, in our terms).</p>
<p><span class="sBold">ChatGPT(Plus)&nbsp;</span><a class="s6" href="#bookmark112">[112]</a>: Study of profi-</span> ciency of GPTs vs fine-tuned version.</p>
</td>
</tr>
<tr style="height: 17pt;">
<td>
<p>Line-Level/Edit-Time Fault/API Misuse Prediction</p>
</td>
<td>
<p><span class="sBold">FLAG&nbsp;</span><a class="s6" href="#bookmark2">[2]</a>: prefix snippet + (suffix snippet) + (prefix of line to be guessed)</span></p>
<p> &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ContextConsistent-Line-Completion⟩</span>&nbsp;&rarr; code line.</span></p>
<p><a class="s6" href="#bookmark8">EditTime&nbsp;</a>[8]: </span><span class="s2">&rarr; </span><span class="s21" style="background-color: #cae6e4;">⟨</span><span class="s22" style="background-color: #cae6e4;">Definition-Recall</span><span class="s21" style="background-color: #cae6e4;">⟩</span><span class="s2"> &rarr; </span>vul task descrip;</span></p>
<p>code language + vul type </span><span class="s2">&rarr; </span><span class="s21" style="background-color: #cae6e4;">⟨</span><span class="s22" style="background-color: #cae6e4;">Example-Recall</span><span class="s21" style="background-color: #cae6e4;">⟩</span><span class="s2"> &rarr; </span>examp;</span></p>
<p>code snip </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-VulnerabilityProneness-Code-OneClass-Classification</span><span class="s16" style="background-color: #d6df8c;">⟩</span></p>
<p class="s2" style="padding-left: 6pt; text-indent: 0pt; line-height: 8pt; text-align: left;">&rarr; yes/no + explan;</span></p>
<p>code snip </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-VulnerabilityProneness-Code-OneClass-Classification</span><span class="s16" style="background-color: #d6df8c;">⟩</span></p>
<p class="s2" style="padding-left: 6pt; text-indent: 0pt; line-height: 8pt; text-align: left;">&rarr; yes/no + explan [Few-Shot: recalled examp].</span></p>
<p><span class="sBold">WitheredLeaf&nbsp;</span><a class="s6" href="#bookmark11">[11]</a>: code </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-SemanticBugPresence-CodeLine-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">OneClass-Classification⟩</span>&nbsp;&rarr; yes/no + (line + reason)</span><span class="s9">+</span>;</span></p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
<p>(code line + reason)</span><span class="s9">+ &rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Warnings-Irrelevance-Filtering⟩</span>&nbsp;&rarr; (line + reason)</span><span class="s9">+</span>;</span></p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
<p>code line + reason </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-BugFixabilityByNameChange-CodeLine-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">OneClass-Classificatio</span><span class="s15">n⟩</span>&nbsp;&rarr; yes/no + fixed-line [CoT: </span><span class="s25" style="background-color: #9fd2ec;">fi</span>x];</span></p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
<p>prev conv + code line + reason </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨ListSemiTargeted-BugCategory-BugExpla-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">nation-MultiClass-Classification⟩</span>&nbsp;&rarr; category.</span></p>
<p><span class="sBold">LLMAPIDet&nbsp;</span><a class="s6" href="#bookmark92">[92]</a>: code before + code after &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨RootCauseOriented-Change-</span></p>
<p><span class="s13" style="background-color: #ecb4cb;">Action-Verbalization⟩</span>&nbsp;&rarr; rule [Few-Shot];</span></p>
<p>code snip (incl. API usage) &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨CodeCorresponding-Intent-Generation⟩</span>&nbsp;&rarr; NL</span> description; code snip + API usage + (potential misuses rules) <span class="s2">&rarr;</span></p>
<p><span class="s16" style="background-color: #d6df8c;">⟨</span><span class="s18" style="background-color: #d6df8c;">GivenAPIMisuseRulesCompliance-Code-OneClass-Classification⟩</span>&nbsp;&rarr; yes/no</span> [RAG].</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
</td>
<td>
<p><span class="sBold">FLAG&nbsp;</span><a class="s6" href="#bookmark2">[2]</a>: LLM is used as line genera-</span> tor (preprocessor). A bounded number of attempts with hints is tried to get non empty line. Feature extraction based on edit distances and Bleu. Logprobs of tokens are used when available. Classification is done based on such features.</p>
<p><span class="sBold">EditTime&nbsp;</span><a class="s6" href="#bookmark8">[8]</a>: Comparative study also</span> against a fine-tuning approach. Retrieval is done to find adequate task description and examples for the few-shot learning approach.</p>
<p><span class="sBold">WitheredLeaf&nbsp;</span><a class="s6" href="#bookmark11">[11]</a>: Lightweight, open-</span> source models (e.g., infilling ones) are used to identify suspicious program entities as a preprocessing step. Last tasks are implemented by same prompt.</p>
<p><span class="sBold">LLMAPIDet&nbsp;</span><a class="s6" href="#bookmark92">[92]</a>: Study on DL API</span> Misuse Root Causes that feed LLM-based solution. Misuse rules populates a DB and examples for misuses detection. Potential misuse rule list by cosine similarity between the code explanation obtained in step 2 and each misuse rule in DB. Patching step is not shown in this report.</p>
</td>
</tr>
<tr style="height: 17pt;">
<td>
<p class="s1" style="padding-top: 5pt; padding-left: 5pt; text-indent: 0pt; line-height: 9pt; text-align: left;">Vulnerability Detection for Smart Contracts</p>
</td>
<td>
<p style="padding-top: 5pt; padding-left: 6pt; text-indent: 0pt; line-height: 9pt; text-align: left;"><span class="sBold">ChatGPTSCV&nbsp;</span><a class="s6" href="#bookmark10">[10]</a>: src smrt contrct + tgt vuls </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-ListTar-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">geted-CWEVulnerabilityProneness-Code-MultiLabel-Classification⟩</span>&nbsp;&rarr; assessment</span> [CoT];</p>
<p>vul classes + assess &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨AssessmentBased-Vulnerability-MultiClass-</span></p>
<p><span class="s13" style="background-color: #ecb4cb;">Summarization⟩</span>&nbsp;&rarr; list (vul class, DerivedBinaryVerdict) [CoT].</span></p>
<p><span class="sBold">SmartAudit&nbsp;</span><a class="s6" href="#bookmark17">[17]</a>: contract src-code + vul type + vul descr </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨ListTargeted-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">CWEVulnerabilityProneness-Code-OneClass-Classification⟩</span>&nbsp;&rarr; yes/no;</span></p>
<p>contract src-code </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-VulnerabilityProneness-Code-MultiLabel-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">Classification⟩</span>&nbsp;&rarr; vuls descr;</span></p>
<p>contract src-code + prev conv + (focal funct name) </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-Vulner</span><span class="s18" style="background-color: #d6df8c;">abilityProneness-Code-MultiLabel-Classification⟩</span>&nbsp;&rarr; vuls descr + (fix recom)</span></p>
<p>[CoT: </span><span class="s25" style="background-color: #ecb4cb;">intent</span> + thoughts].</span></p>
<p><span class="sBold">GPTLens&nbsp;</span><a class="s6" href="#bookmark33">[33]</a>: src-code </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-VulnerabilityProneness-Code-MultiL</span><span class="s18" style="background-color: #d6df8c;">abel-Classification⟩</span>&nbsp;&rarr; (vul + funct name + reason)</span><span class="s4">&lowast;</span> (auditor);</span></p>
<p>src-code + vul + funct name + reason </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Audits-Qlty(Correctness, Severity,</span></p>
<p><span class="s18" style="background-color: #d6df8c;">Profitability)-Assessment⟩</span>&nbsp;&rarr; score + explan (critic).</span></p>
<p><span class="sBold">LLM4Vuln&nbsp;</span><a class="s6" href="#bookmark80">[80]</a>: vul report + tgt code &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨CodeCorresponding-Intent-</span></p>
<p><span class="s13" style="background-color: #ecb4cb;">Verbalization⟩</span>&nbsp;&rarr; operational summary (funct.summ.);</span></p>
<p>vul report &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨Vulnerability-MechanismExplanation-Summarization</span><span class="s12" style="background-color: #ecb4cb;">⟩ </span><span class="s2"> &rarr; </span>abstract</span></p>
<p class="s1" style="padding-left: 5pt; text-indent: 0pt; line-height: 8pt; text-align: left;">vul (abs.gen.); tgt code + (DB.MatchVulReport(TC)) (Alt1) +</p>
<p>(DB.MatchAbsVulKnow(funct.summ.(TC)) (Alt2) </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨InfoRequesting-</span><span class="s18" style="background-color: #d6df8c;">Rationalized-GivenVulnDescrProneness-Code-MultiLabel-Classification</span><span class="s16" style="background-color: #d6df8c;">⟩</span><span class="s2"> &rarr;</span></p>
<p>yes/no + (type of vul), (reason) [Pre-CoT: </span><span class="s25" style="background-color: #ecb4cb;">functional summary</span> + explicit</span></p>
<p>errors &mdash; Post-CoT: </span><span class="s25" style="background-color: #9fd2ec;">patch</span> or </span><span class="s25" style="background-color: #d3bfd7;">Proof of Concept exploit</span>, ReAct: getFunc-</span> tionDefinition, getClassInheritance, getVariableDefinition, RAG: Alt1,</p>
<p class="s1" style="padding-left: 5pt; text-indent: 0pt; line-height: 8pt; text-align: left;">Alt2]. <span class="sBold">GPTScan&nbsp;</span><a class="s6" href="#bookmark81">[</a>81]: (scenario)<span class="s4">&lowast;</span> + contract src-code <span class="s2">&rarr;</span></p>
<p><span class="s16" style="background-color: #d6df8c;">⟨</span><span class="s18" style="background-color: #d6df8c;">GivenCharacteristicsCorrespondenc</span><span class="s15">e</span><span class="s18" style="background-color: #d6df8c;">-Code-OneClass-Classificatio</span><span class="s15">n</span><span class="s16" style="background-color: #d6df8c;">⟩</span><span class="s2"> &rarr;</span></p>
<p class="s1" style="padding-left: 5pt; text-indent: 0pt; line-height: 8pt; text-align: left;">yes/no [CoT: mimic in the background] (1);</p>
<p>scenario + prop + contract src-code </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨GivenBehaviorCorrespondence-Code-</span></p>
<p><span class="s18" style="background-color: #d6df8c;">OneClass-Classification⟩</span>&nbsp;&rarr; yes/no [CoT: mimic in the background];</span></p>
<p>src-code </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">RoleBased-CodeElements-Identification⟩</span>&nbsp;&rarr; vars/statements [CoT:</span> mimic in the background].</p>
</td>
<td>
<p><a class="s6" href="#bookmark10">ChatGPTSCV&nbsp;</a>[10]: Empirical study.</p>
<p><span class="sBold">SmartAudit&nbsp;</span><a class="s6" href="#bookmark17">[17]</a>: Potentiality study of</span> LLMs to find smart contract vulnerabilities. Binary, non-binary, CoT prompts are presented. CoT version is performed by iteratively asking LLM to audit each function name, revisiting audit or linking functions to find vulnerabilities.</p>
<p><span class="sBold">GPTLens&nbsp;</span><a class="s6" href="#bookmark33">[33]</a>: Several auditors solv-</span> ing detection task generate potential vulnerabilities. A critic assess them.</p>
<p><span class="sBold">LLM4Vuln&nbsp;</span><a class="s6" href="#bookmark80">[80]</a>: Evaluation framework</span> that includes LLM-based Result Annotation and Analysis (not reported here).</p>
<p class="s1" style="padding-left: 5pt; text-indent: 0pt; line-height: 8pt; text-align: left;">Vector DB are populated using abstract-generation and functionalsummary to match in analysis time relevant summarized vulnerability knowledge (Alt2). aw version is based on a DB matching reports to vulnerable code (Alt1). LLM seeks extra context through LLM&rsquo;s function calling mechanism.</p>
<p><span class="sBold">GPTScan&nbsp;</span><a class="s6" href="#bookmark81">[81]</a>: Authors break down</span> common logic vulnerability types into scenarios and properties. LLMs scenario and property matches and identified variables are validated by static confirmation. Saving on GPT costs by first filtering in a single prompt (1).</p>
</td>
</tr>
</tbody>
</table>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
<p style="padding-left: 8pt; text-indent: 0pt; text-align: left; font-size: 12pt;"><b>Table 4:</b> SE task: Static Analysis.</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
<table style="border-collapse: collapse; margin-left: 6.25pt;" cellspacing="0">
<tbody>
<tr style="height: 30pt;">
<td style="width: 99pt; border-width: 1pt; border-style: solid;" bgcolor="#DDC8D5">
<p>SE Problem</p>
</td>
<td style="width: 520pt; border-width: 1pt; border-style: solid;" bgcolor="#DDC8D5">
<p>LLM Downstream Tasks<br>(input</span>&rarr; ⟨<span class="s3">type of task </span>⟩ &rarr;output[learn. strat.])</span><span class="s4">&lowast;</span></p>
</td>
<td style="width: 320pt; border-width: 1pt; border-style: solid;" bgcolor="#DDC8D5">
<p>Architectural Notes</p>
</td>
</tr>
<tr style="height: 68pt;">
<td>
<p>Call-Graph/CFG Construction</p>
</td>
<td>
<p style="padding-top: 5pt; padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: left;"><span class="sBold">CFG-Chain&nbsp;</span><a class="s6" href="#bookmark36">[36]</a>: code </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">CodeBlocks-Extraction⟩</span>&nbsp;&rarr; nested code-blocks [Few-Shot];</span></p>
<p style="padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: left;">code + nstd code-blocks </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">BlockCorresponding-Code-Extraction⟩</span>&nbsp;&rarr; basic code-blocks [Few-Shot];</span></p>
<p style="padding-left: 6pt; padding-right: 38pt; text-indent: 0pt; text-align: left;">code-block &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨ControlFlow-Identification⟩</span>&nbsp;&rarr; CFG [Few-Shot]; CFGs &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨CFG-Fusion⟩</span>&nbsp;&rarr; CFG [Few-Shot].</span></p>
</td>
<td>
<p class="sBold" style="padding-top: 5pt; padding-left: 5pt; padding-right: 5pt; text-indent: 0pt; text-align: justify;">CFG-Chain&nbsp;</span><a class="s6" href="#bookmark36">[36]</a>: LLMs are invoked in a chain of subtasks: structure hierarchy extraction (translation), nested block extraction (completer), Basic code CFG (translation) and graph fusion.</span></p>
</td>
</tr>
<tr style="height: 77pt;">
<td>
<p>Use Before Initialize</p>
</td>
<td>
<p><span class="sBold">LLift&nbsp;</span><a class="s6" href="#bookmark51">[51]</a>: use site + (retrv code snip) </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">InfoRequesting-Initializator-</span> <span class="s18" style="background-color: #f3d2b7;">Identification⟩</span>&nbsp;&rarr; (retrv rqst) + initializer [ReAct: funct to retrv];</span></p>
<p style="padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: justify;">use site + init sig &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨PostConstraint-Identification⟩</span>&nbsp;&rarr; post-constr on init results [</span><span class="s25" style="background-color: #d6df8c;">Self-Validation</span>];</span></p>
<p>init invoc + post-constr + var focus &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨InfoRequesting-QualifiedPostCondi-</span> <span class="s13" style="background-color: #ecb4cb;">tion-Characterization⟩</span>&nbsp;&rarr; (retrv rqst) + may-must init-post [Few-Shot, CoT, ReAct, </span><span class="s25" style="background-color: #d6df8c;">Self-Validation</span>].</span></p>
</td>
<td>
<p class="sBold" style="padding-top: 5pt; padding-left: 6pt; padding-right: 3pt; text-indent: 0pt; text-align: justify;">LLift&nbsp;</span><a class="s6" href="#bookmark51">[51]</a>: Post-constraint guided path analysis to verify the path feasibility of the &ldquo;use&rdquo; of an initialized variable. Static analyzer upstream; two conversations ((1) init detect./post-constraint generation (2) summarization): multiple iterations each. Majority voting.</span></p>
</td>
</tr>
<tr style="height: 105pt;">
<td>
<p class="s1" style="padding-top: 5pt; text-indent: 0pt; text-align: center;">Resource Leak</p>
</td>
<td>
<p style="padding-top: 5pt; padding-left: 6pt; padding-right: 4pt; text-indent: 0pt; text-align: left;"><span class="sBold">SkipAnalyzer&nbsp;</span><a class="s6" href="#bookmark65">[65]</a>: code snip </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-NullDerreferencePresence-Code-</span> <span class="s18" style="background-color: #d6df8c;">OneClass-Classification⟩</span>&nbsp;&rarr; yes/no + vul descr [CoT, One-Shot, Few-Shot]; code snip </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-ResourceLeakPresence-Code-OneClass-Classification</span><span class="s16" style="background-color: #d6df8c;">⟩</span></p>
<p class="s2" style="padding-left: 6pt; text-indent: 0pt; text-align: left;">&rarr; yes/no + vul descr [CoT, One-Shot, Few-Shot];</span></p>
<p>code snip + warning </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Warning-FalsePositiveProneness-Assessment⟩</span>&nbsp;&rarr; verdict [CoT, One-Shot, Few-Shot].</span></p>
<p><span class="sBold">InferROI&nbsp;</span><a class="s6" href="#bookmark91">[91]</a>: snip </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">ResourceLeakRelated-CodeElements-Identification</span><span class="s19" style="background-color: #f3d2b7;">⟩</span><span class="s2"> &rarr;</span></p>
<p class="s1" style="padding-left: 6pt; text-indent: 0pt; text-align: left;">leakable resources + acquisition/releasing calls + closed if-conds.</p>
</td>
<td>
<p class="sBold" style="padding-top: 5pt; padding-left: 6pt; padding-right: 3pt; text-indent: 0pt; text-align: justify;">SkipAnalyzer&nbsp;</span><a class="s6" href="#bookmark65">[65]</a>: The pipeline analyzes snippets by using LLMs and static analysis tools like Infer. LLM is also used to filter false-positive warnings. LLMs are used to fix code as well (out of scope).</span></p>
<p style="text-align: justify;"><span class="sBold">InferROI&nbsp;</span><a class="s6" href="#bookmark91">[91]</a>: LLM is used to get intentions in code, then a static resource leak detection engine is feed with this information.</span></p>
</td>
</tr>
<tr style="height: 124pt;">
<td>
<p class="s1" style="padding-top: 5pt; padding-left: 5pt; padding-right: 20pt; text-indent: 0pt; text-align: left;">Data-Flow Analysis</p>
</td>
<td>
<p><span class="sBold">LLMDFA&nbsp;</span><a class="s6" href="#bookmark90">[90]</a>: AST-traversal skel + (suggested identif rules) &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Source/Sink-</span> <span class="s8" style="background-color: #9fd2ec;">ElementIdentificationCode-Completion⟩</span>&nbsp;&rarr; source/sink extractor [Few-Shot: </span><span class="s29">E</span><span class="s30">spec</span><span class="s31">];</span></p>
<p class="s31" style="padding-left: 6pt; padding-right: 4pt; text-indent: 0pt; text-align: justify;">AST-traversal skel + suggested identif rules + <span class="s29">E</span><span class="s30">spec </span>+ prev candidate extractor script + (error msg on <span class="s29">E</span><span class="s30">spec</span>) + (false pos on <span class="s29">E</span><span class="s30">spec</span>) + (false neg on <span class="s29">E</span><span class="s30">spec</span>)</p>
<p style="padding-left: 5pt; padding-right: 5pt; text-indent: 0pt; text-align: justify;"> &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Source/Sink-ElementIdentificationCode-Correction⟩</span>&nbsp;&rarr; candidate extractor; code snip + &iexcl;var, line&iquest; + &iexcl;var, line&iquest; &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨VariablesSameValue-Identification⟩</span>&nbsp;&rarr; yes/no [CoT, Few-Shot: incl though];</span></p>
<p>script skeleton + path information &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨PathConditionEncoding-Code-</span> <span class="s8" style="background-color: #9fd2ec;">Completion⟩</span>&nbsp;&rarr; candidate script;</span></p>
<p class="s1" style="padding-left: 6pt; text-indent: 0pt; text-align: justify;">script skeleton + path information + prev candidate script + error msgs <span class="s2">&rarr;</span></p>
<p><span class="s7" style="background-color: #9fd2ec;">⟨</span><span class="s8" style="background-color: #9fd2ec;">PathConditionEncoding-Code-Correction⟩</span>&nbsp;&rarr; candidate script.</span></p>
</td>
<td>
<p class="sBold" style="padding-top: 5pt; padding-left: 5pt; text-indent: 0pt; text-align: left;">LLMDFA&nbsp;</span><a class="s6" href="#bookmark90">[90]</a>: LLMs are used together with solvers, parser and ad-hoc code.</span></p>
</td>
</tr>
<tr style="height: 124pt;">
<td>
<p class="s1" style="padding-top: 5pt; text-indent: 0pt; text-align: center;">Taint Analysis</p>
</td>
<td>
<p style="padding-top: 6pt; padding-left: 6pt; padding-right: 3pt; text-indent: 0pt; text-align: justify;"><span class="sBold">E&amp;V&nbsp;</span><a class="s6" href="#bookmark29">[29]</a>: task input + static-analysis pseudo-code + relevant src-code + prev results + verif fdbk &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨Step-Computation⟩</span>&nbsp;&rarr; round output + (retrv-rqst)</span><span class="s9">0...1</span>;</span></p>
<p>exec specs + relev src-code + pesudo-code + round output </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Behavior-Cor-</span> <span class="s18" style="background-color: #d6df8c;">rectness-Assessment⟩</span>&nbsp;&rarr; verif fdbk.</span></p>
<p style="padding-left: 6pt; text-indent: 0pt; line-height: 9pt; text-align: justify;"><a class="s6" href="#bookmark55">LATTE&nbsp;</a>[55]: name + (code)</span><span class="s9">0...1</span> <span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">Sink-Identification⟩</span>&nbsp;&rarr; sink;</span></p>
<p style="padding-left: 6pt; padding-right: 5pt; text-indent: 0pt; text-align: justify;">name + (code)</span><span class="s9">0...1</span> <span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">ExternalInputSource-Identification⟩</span>&nbsp;&rarr; external input source;</span></p>
<p style="padding-left: 5pt; text-indent: 0pt; line-height: 9pt; text-align: justify;">(prev conv) + code snip + taint srcs + taint info &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨TaintFlow-Identification</span><span class="s12" style="background-color: #ecb4cb;">⟩</span>&nbsp;&rarr; deduced data flow [incr prompt seq];</span></p>
<p>prompt seq results </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Rationalized-TaintFlowAnalysisEnhanced-CWEVulnerabil-</span> <span class="s18" style="background-color: #d6df8c;">ityProneness-Code-MultiLabel-Classification⟩</span>&nbsp;&rarr; (vul)</span><span class="s9">+</span>.</span></p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">E&amp;V&nbsp;</span><a class="s6" href="#bookmark29">[29]</a>: General framework for conducting static analysis from pseudo-code by means of LLMs. Agent-based architecture, but hard-coded planning strategies. Augment temperature if re-analysis required.</span></p>
<p style="text-align: justify;"><span class="sBold">LATTE&nbsp;</span><a class="s6" href="#bookmark55">[55]</a>: LLMs are invoked to identify sources and sinks. Dangerous flows are analyzed step by step by LLMs in a prompt sequence driven by sliced code.</span></p>
</td>
</tr>
<tr style="height: 30pt;">
<td>
<p class="s1" style="padding-top: 5pt; padding-right: 4pt; text-indent: 0pt; text-align: center;">Static Slicing</p>
</td>
<td>
<p><span class="sBold">SimulinkSlicer&nbsp;</span><a class="s6" href="#bookmark61">[61]</a>: model + requirement </span><span class="s2">&rarr; </span><span class="s19" style="background-color: #f3d2b7;">⟨</span><span class="s18" style="background-color: #f3d2b7;">Model-Slicing⟩</span>&nbsp;&rarr; model components [Few-Shot, CoT: dependence chain elicitation by demonstration].</span></p>
</td>
<td>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
</td>
</tr>
<tr style="height: 58pt;">
<td>
<p>Fix Acceptance Check</p>
</td>
<td>
<p><span class="sBold">CORE&nbsp;</span><a class="s6" href="#bookmark89">[89]</a>: diff </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Patch-Qlty(Fixes, LeastImpact)-Assessment⟩</span>&nbsp;&rarr; score + reason.</span></p>
</td>
<td>
<p style="text-align: justify;"><span class="sBold">CORE&nbsp;</span><a class="s6" href="#bookmark89">[89]</a>: Proposer LLM generates potential code revisions (not shown here). Static analysis is run on those revisions. Reviewer ranks solutions for specific fix warnings.</span></p>
</td>
</tr>
</tbody>
</table>
<p style="padding-top: 1pt; text-indent: 0pt; text-align: left;">&nbsp;</p>
<p style="padding-left: 8pt; text-indent: 0pt; text-align: left; font-size: 12pt;"><b>Table 5:</b> SE task: Program Verification.</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
<table style="border-collapse: collapse; margin-left: 6.25pt;" cellspacing="0">
<tbody>
<tr style="height: 30pt;">
<td style="width: 99pt; border-width: 1pt; border-style: solid;" bgcolor="#F7CBCB">
<p>SE Problem</p>
</td>
<td style="width: 520pt; border-width: 1pt; border-style: solid;" bgcolor="#F7CBCB">
<p>LLM Downstream Tasks<br>(input</span>&rarr; ⟨<span class="s3">type of task </span>⟩ &rarr;output[learn. strat.])</span><span class="s4">&lowast;</span></p>
</td>
<td style="width: 320pt; border-width: 1pt; border-style: solid;" bgcolor="#F7CBCB">
<p>Architectural Notes</p>
</td>
</tr>
<tr style="height: 17pt;">
<td>
<p>Program</p>
<p class="s1" style="padding-left: 5pt; text-indent: 0pt; line-height: 8pt; text-align: left;">Verification</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
</td>
<td>
<p style="padding-top: 5pt; padding-left: 5pt; text-indent: 0pt; line-height: 10pt; text-align: left;"><span class="sBold">AlloyRepair&nbsp;</span><a class="s6" href="#bookmark3">[3]</a>: faulty spec + (generic-feedback)</span><span class="s9">0...1</span> &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨FeedbackGuided-</span></p>
<p><span class="s8" style="background-color: #9fd2ec;">Specification-Correction⟩</span>&nbsp;&rarr; fixed spec (repair agent);</span></p>
<p>faulty spec + suggestion &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨SuggestionGuided-Specification-Correction⟩</span><span class="s2"> &rarr;</span> fixed spec (repair agent);</p>
<p>report feedback + faulty spec &rarr;&nbsp;<span class="s7" style="background-color: #d3bfd7;">⟨Suggestion-Generation⟩</span>&nbsp;&rarr; suggestion</span></p>
<p class="s1" style="padding-left: 5pt; text-indent: 0pt; line-height: 8pt; text-align: left;">(prompt agent).</p>
<p><span class="sBold">ChatInv&nbsp;</span><a class="s6" href="#bookmark40">[40]</a>: code + loc + masked assert &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Assertion-Completion⟩</span>&nbsp;&rarr; assert</span> [InFiller].</p>
<p><span class="sBold">Loopy&nbsp;</span><a class="s6" href="#bookmark43">[43]</a>: annot prgm with prop to be verif </span><span class="s2">&rarr;</span></p>
<p><span class="s7" style="background-color: #9fd2ec;">⟨</span><span class="s8" style="background-color: #9fd2ec;">Inductive&amp;SufficientLoopInvariant-Assertion-Generation⟩</span>&nbsp;&rarr; prgm an-</span> not with set of loop assert;</p>
<p>annot prgm + verif fdbk &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨SyntaxInductivenessSufficiency</span><span class="s15">Aw</span><span class="s8" style="background-color: #9fd2ec;">ar</span><span class="s15">e</span><span class="s8" style="background-color: #9fd2ec;">-Assertion-</span></p>
<p><span class="s8" style="background-color: #9fd2ec;">Correction⟩</span>&nbsp;&rarr; annot prgm.</span></p>
<p><span class="sBold">SpecGen&nbsp;</span><a class="s6" href="#bookmark62">[62]</a>: prgm &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨CodeCorresponding-Specification-Generation⟩</span>&nbsp;&rarr; prgm</span></p>
<p class="s1" style="padding-left: 5pt; text-indent: 0pt; line-height: 8pt; text-align: left;">with specs [Few-Shot];</p>
<p>prev conv + curated verif fdbk &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ErrorAware-Specification-Correction⟩</span><span class="s2"> &rarr;</span> prgm with specs [Few-Shot].</p>
<p><span class="sBold">Dafny-Synth&nbsp;</span><a class="s6" href="#bookmark64">[64]</a>: intent &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨IntentCorresponding-AnnotatedCode-Generation⟩</span>&nbsp;&rarr; annot code (contextless);</span></p>
<p>intent + sig + tests &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Intent&amp;TestsCorresponding-AnnotatedCode-Generation⟩</span></p>
<p class="s2" style="padding-left: 6pt; text-indent: 0pt; line-height: 8pt; text-align: left;">&rarr; annot code (signature);</span></p>
<p>intent &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨IntentCorresponding-Signature-Generation⟩</span>&nbsp;&rarr; sig (dynamic);</span></p>
<p>intent + sig &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨NL-Specification-Distillation⟩</span>&nbsp;&rarr; <span class="s25" style="background-color: #ecb4cb;">pre/post</span> spec (dynamic);</span></p>
<p>intent + sig + spec &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Intent&amp;SignatureCorresponding-Provable-Annotated-</span></p>
<p><span class="s8" style="background-color: #9fd2ec;">Code-Generation⟩</span>&nbsp;&rarr; anno code [RAG + Few-Shot: retrieved simil] (dynamic).</span></p>
<p><span class="sBold">Clover&nbsp;</span><a class="s6" href="#bookmark79">[79]</a>: annot code skel + verifier fdbk &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨VerifierAware-AnnotationCor-</span></p>
<p><span class="s8" style="background-color: #9fd2ec;">responding-Code-InFilling⟩</span>&nbsp;&rarr; code (anno2code);</span></p>
<p>annot code skel + compiler fdbk &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨CompilerAware-AnnotationCorresponding-</span></p>
<p><span class="s8" style="background-color: #9fd2ec;">Code-InFilling⟩</span>&nbsp;&rarr; code (anno-complete);</span></p>
<p>intent + annot code skel + compiler fdbk &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨IntentCorresponding-Code-</span></p>
<p><span class="s8" style="background-color: #9fd2ec;">InFilling⟩</span>&nbsp;&rarr; code (doc2code);</span></p>
<p>annot code &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨CodeCorresponding-Intent-Verbalization⟩</span>&nbsp;&rarr; docstrings</span></p>
<p class="s1" style="padding-left: 5pt; text-indent: 0pt; line-height: 8pt; text-align: left;">(code2doc);</p>
<p>code &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨HoareValid-Annotation-Completion⟩</span>&nbsp;&rarr; pre/postcond (code2anno);</span></p>
<p>funct sig with docstring + comp fdbk &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨IntentCorresponding-PrePost-</span></p>
<p><span class="s13" style="background-color: #ecb4cb;">Formalization⟩</span>&nbsp;&rarr; annot code with pre and post (doc2anno);</span></p>
<p>annotation &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨AnnotationCorresponding-Intent-Verbalization⟩</span>&nbsp;&rarr; docstrings</span></p>
<p class="s1" style="padding-left: 5pt; text-indent: 0pt; line-height: 8pt; text-align: left;">(anno2doc);</p>
<p>docstring + docstring </span>&rarr;&nbsp;<span class="s7" style="background-color: #d6df8c;">⟨Docstrings-Equivalence-Checking⟩</span>&nbsp;&rarr; yes/no (doc-</span> string equiv check).</p>
<p><span class="sBold">AutoSpec&nbsp;</span><a class="s6" href="#bookmark93">[93]</a>: masked annotated-code &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Annotation-Generation⟩</span><span class="s2"> &rarr;</span></p>
<p class="s1" style="padding-left: 5pt; text-indent: 0pt; line-height: 8pt; text-align: left;">(pre/post/inv) annotated-code [Few-Shot].</p>
<p><span class="sBold">Lemur&nbsp;</span><a class="s6" href="#bookmark94">[94]</a>: code under analysis + place holder &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Invariant-Lemma-</span></p>
<p><span class="s8" style="background-color: #9fd2ec;">Generation⟩</span>&nbsp;&rarr; assert;</span></p>
<p>code under analysis + place holder + assert + issue &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Invariant-Lemma-</span></p>
<p><span class="s8" style="background-color: #9fd2ec;">Correction⟩</span>&nbsp;&rarr; assert.</span></p>
<p><span class="sBold">RustProof&nbsp;</span><a class="s6" href="#bookmark102">[102]</a>: annot code (with precond) &rarr;&nbsp;<span class="s7" style="background-color: #ecb4cb;">⟨PostCondition-Generation</span><span class="s12" style="background-color: #ecb4cb;">⟩</span></p>
<p><span class="s2">&rarr; </span>annot code (with pre/post) [CoT: </span><span class="s25" style="background-color: #ecb4cb;">code intent + precond explan</span>];</span></p>
<p>annot src-code sgmnt &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨Invariant-Lemma-Generation⟩</span>&nbsp;&rarr; sgmnt-with-proof</span></p>
<p>[Few-Shot, CoT: </span><span class="s25" style="background-color: #ecb4cb;">precond explan + postcond explan</span> + inv explan + proof</span> explan];</p>
<p>annot src-code sgmnt + last answer + model checker error &rarr;&nbsp;<span class="s7" style="background-color: #9fd2ec;">⟨ErrorAware-</span><span class="s8" style="background-color: #9fd2ec;">Lemma-Correction⟩</span>&nbsp;&rarr; sgmnt-with-proof [CoT].</span></p>
</td>
<td>
<p><span class="sBold">AlloyRepair&nbsp;</span><a class="s6" href="#bookmark3">[3]</a>: Alloy analyzer is used</span> to validate an generate a report that is either used as input for correction or processed by an LLM to generate a efined suggestion.</p>
<p><span class="sBold">Loopy&nbsp;</span><a class="s6" href="#bookmark43">[43]</a>: Invariants are checked by</span> using symbolic tools. Assertions collected trough several LLM invocations.</p>
<p class="s1" style="padding-left: 5pt; text-indent: 0pt; line-height: 8pt; text-align: left;">Then it checks (in linear time) if there exists a subset that is inductive and sufficient. Repair takes into account categorized feedback and dependence relation between assertions.</p>
<p><span class="sBold">SpecGen&nbsp;</span><a class="s6" href="#bookmark62">[62]</a>: Tasks models first</span> phase of the approach: a conversation-driven specification generation leveraging LLMs.</p>
<p><span class="sBold">Clover&nbsp;</span><a class="s6" href="#bookmark79">[79]</a>: Consistency checks to</span> know (i) the code is functionally correct</p>
<p class="s1" style="padding-left: 5pt; text-indent: 0pt; line-height: 9pt; text-align: left;">with respect to its annotation; (ii) the annotation captures the full functionality of the code; and (iii) the DocString also accurately reflects the functionality of the code. Deductive checker and tests are used to prove annotated programs and equivalence between reconstructed artifacts.</p>
<p><span class="sBold">AutoSpec&nbsp;</span><a class="s6" href="#bookmark93">[93]</a>: Call graph is used to</span> identify locations and order for specification generation.</p>
<p><span class="sBold">Lemur&nbsp;</span><a class="s6" href="#bookmark94">[94]</a>: Integrated with verifiers, it</span> follows a set of proof rules that invokes LLMs to act as suggesters of auxiliary assertions and repairer of those suggestions.</p>
<p><span class="sBold">RustProof&nbsp;</span><a class="s6" href="#bookmark102">[102]</a>: Proof helper in-</span> tegrated with smart contract model checker. Human and static analysis tools can be integrated to improve generation.</p>
</td>
</tr>
</tbody>
</table>
<h1 style="padding-top: 15pt; padding-left: 6pt; text-indent: 0pt; text-align: left;">References</h1>
<ol id="l1">
<li data-list-text="[1]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -14pt; text-align: justify;"><a name="bookmark1"></a>&zwnj;Joshua Ackerman and George Cybenko. Large language models for fuzzing parsers (Registered report). In Marcel B&uml;ohme, Yannic Noller, Baishakhi Ray, and L&aacute;szl&oacute; Szekeres, editors, <span class="s32">FUZZING 2023: 2nd International Fuzzing Workshop</span>, pages 31&ndash;38, New York, NY, USA,&nbsp;<a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3605157.3605173" target="_blank" rel="noopener">2023. ACM,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3605157.3605173</span>.</p>
</li>
<li data-list-text="[2]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -15pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2306.12643" target="_blank" rel="noopener" name="bookmark2">Baleegh Ahmad, Benjamin Tan, Ramesh Karri, and Hammond Pearce. FLAG: Finding line anomalies (in code) with generative AI, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2306.12643</span>.</p>
</li>
<li data-list-text="[3]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -15pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2404.11050" target="_blank" rel="noopener" name="bookmark3">Mohannad Alhanahnah, Md Rashedul Hasan, and Hamid Bagheri. An empirical evaluation of pre-trained large language models for repairing declarative formal specifications, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2404.11050</span>.</p>
</li>
<li data-list-text="[4]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -14pt; text-align: justify;"><a name="bookmark4"></a>&zwnj;Nadia Alshahwan, Jubin Chheda, Anastasia Finogenova, Beliz Gokkaya, Mark Harman, Inna Harper, Alexandru Marginean, Shubho Sengupta, and Eddy Wang. Automated unit test improvement using large language models at Meta. In Marcelo d&rsquo;Amorim, editor, <span class="s32">Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering, FSE 2024, Porto de Galinhas, Brazil, July 15-19, 2024</span>, pages 185&ndash;196. ACM,</p>
<p style="padding-left: 31pt; text-indent: 0pt; line-height: 12pt; text-align: left;"><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3663529.3663839" target="_blank" rel="noopener">2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3663529.3663839</span>.</p>
</li>
<li data-list-text="[5]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -15pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2402.04380" target="_blank" rel="noopener" name="bookmark5">Nadia Alshahwan, Mark Harman, Inna Harper, Alexandru Marginean, Shubho Sengupta, and Eddy Wang. Assured LLM-based software engineering, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2402.04380</span>. Presented as a Keynote at InteNSE 24: ACM International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering, April, 2024, Lisbon, Portugal.</p>
</li>
<li data-list-text="[6]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -15pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2206.01335" target="_blank" rel="noopener" name="bookmark6">Patrick Barei&szlig;, Beatriz Souza, Marcelo d&rsquo;Amorim, and Michael Pradel. Code generation tools (almost) for free? A study of few-shot, pre-trained language models on code, 2022,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2206.01335</span>.</p>
</li>
<li data-list-text="[7]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -15pt; text-align: justify;"><a name="bookmark7"></a>&zwnj;Shreya Bhatia, Tarushi Gandhi, Dhruv Kumar, and Pankaj Jalote. Unit test generation using generative AI: A comparative performance analysis of autogeneration tools. In <span class="s32">LLM4Code&rsquo;24, April 20, 2024, Lisbon, Portugal</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3643795.3648396" target="_blank" rel="noopener">, pages 38:1&ndash;38:8. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3643795.3648396</span>.</p>
</li>
<li data-list-text="[8]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -15pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2306.01754" target="_blank" rel="noopener" name="bookmark8"> Aaron Chan, Anant Kharkar, Roshanak Zilouchian Moghaddam, Yevhen Mohylevskyy, Alec Helyar, Eslam Kamal, Mohamed Elkamhawy, and Neel Sundaresan. Transformer-based vulnerability detection in code at EditTime: Zero-shot, few-shot, or fine-tuning?, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2306.01754</span>.</p>
</li>
<li data-list-text="[9]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -14pt; text-align: justify;"><a name="bookmark9"></a>&zwnj;Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu Chen. CodeT: Code generation with generated tests. In <span class="s32">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</span>. OpenReview.net, 2023.</p>
</li>
<li data-list-text="[10]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2309.05520" target="_blank" rel="noopener" name="bookmark10">Chong Chen, Jianzhong Su, Jiachi Chen, Yanlin Wang, Tingting Bi, Yanli Wang, Xingwei Lin, Ting Chen, and Zibin Zheng. When ChatGPT meets smart contract vulnerability detection: How far are we?, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2309.05520</span>.</p>
</li>
<li data-list-text="[11]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2405.01668" target="_blank" rel="noopener" name="bookmark11">Hongbo Chen, Yifan Zhang, Xing Han, Huanyao Rong, Yuheng Zhang, Tianhao Mao, Hang Zhang, XiaoFeng Wang, Luyi Xing, and Xun Chen. WitheredLeaf: Finding entity-inconsistency bugs with LLMs, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2405.01668</span>.</p>
</li>
<li data-list-text="[12]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark12"></a>&zwnj;Xinyun Chen, Maxwell Lin, Nathanael Sch&uml;arli, and Denny Zhou. Teaching large language models to self-debug. In <span class="s32">The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024</span>. OpenReview.net, 2024.</p>
</li>
<li data-list-text="[13]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark13"></a>&zwnj;Yinfang Chen, Huaibing Xie, Minghua Ma, Yu Kang, Xin Gao, Liu Shi, Yunjie Cao, Xuedong Gao, Hao Fan, Ming Wen, Jun Zeng, Supriyo Ghosh, Xuchao Zhang, Chaoyun Zhang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, and Tianyin Xu. Automatic root cause analysis via large language models for cloud incidents. In <span class="s32">Proceedings of the Nineteenth European Conference on Computer Systems, EuroSys 2024, Athens, Greece, April 22-25, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3627703.3629553" target="_blank" rel="noopener">, pages 674&ndash;688. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3627703.3629553</span>.</p>
<p style="padding-top: 3pt; text-indent: 0pt; text-align: left;">&nbsp;</p>
</li>
<li data-list-text="[14]">
<p style="padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark14"></a>&zwnj;Yinghao Chen, Zehao Hu, Chen Zhi, Junxiao Han, Shuiguang Deng, and Jianwei Yin. ChatUniTest: A framework for LLM-based test generation. In Marcelo d&rsquo;Amorim, editor, <span class="s32">Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering, FSE 2024, Porto de Galinhas, Brazil, July 15-19, 2024</span>, pages 572&ndash;576.</p>
<p style="padding-left: 31pt; text-indent: 0pt; line-height: 12pt; text-align: left;"><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3663529.3663801" target="_blank" rel="noopener">ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3663529.3663801</span>.</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
</li>
<li data-list-text="[15]">
<p style="padding-top: 7pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark15"></a>&zwnj;Aidan Dakhama, Karine Even-Mendoza, William B. Langdon, H&eacute;ctor D. Men&eacute;ndez, and Justyna Petke. SearchGEM5: Towards reliable Gem5 with search based software testing and large language models. In Paolo Arcaini, Tao Yue, and Erik M. Fredericks, editors, <span class="s32">Search-Based Software Engineering - 15th International Symposium, SSBSE 2023, San Francisco, CA, USA, December 8, 2023, Proceedings</span>, volume 14415 of <span class="s32">Lecture Notes in Computer Science</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1007/978-3-031-48796-5_14" target="_blank" rel="noopener">, pages 160&ndash;166. Springer, 2023,&nbsp;</a><a class="a" href="https://doi.org/10.1007/978-3-031-48796-5_14" target="_blank" rel="noopener">doi:10.1007/978-3-031-48796-5&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">14</span>.</p>
</li>
<li data-list-text="[16]">
<p style="padding-top: 6pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a name="bookmark16"></a>&zwnj;Arghavan Moradi Dakhel, Amin Nikanjam, Vahid Majdinasab, Foutse Khomh, and Michel C. Desmarais. Effective test generation using pre-trained large language models and mutation testing. <span class="s32">Inf. Softw. Technol.</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1016/J.INFSOF.2024.107468" target="_blank" rel="noopener">, 171:107468, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1016/J.INFSOF.2024.107468</span>.</p>
</li>
<li data-list-text="[17]">
<p style="padding-top: 6pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2306.12338" target="_blank" rel="noopener" name="bookmark17">Isaac David, Liyi Zhou, Kaihua Qin, Dawn Song, Lorenzo Cavallaro, and Arthur Gervais. Do you still need a manual smart contract audit?, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2306.12338</span>.</p>
</li>
<li data-list-text="[18]">
<p style="padding-top: 6pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark18"></a>&zwnj;Gelei Deng, Yi Liu, V&iacute;ctor Mayoral Vilches, Peng Liu, Yuekang Li, Yuan Xu, Martin Pinzger, Stefan Rass, Tianwei Zhang, and Yang Liu. PentestGPT: Evaluating and harnessing large language models for automated penetration testing. In Davide Balzarotti and Wenyuan Xu, editors, <span class="s32">33rd USENIX Security Symposium, USENIX Security 2024, Philadelphia, PA, USA, August 14-16, 2024</span>. USENIX Association, 2024.</p>
</li>
<li data-list-text="[19]">
<p style="padding-top: 6pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2305.06018" target="_blank" rel="noopener" name="bookmark19"> Yao Deng, Jiaohong Yao, Zhi Tu, Xi Zheng, Mengshi Zhang, and Tianyi Zhang. TARGET: Automated scenario generation from traffic rules for testing autonomous vehicles, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2305.06018</span>.</p>
</li>
<li data-list-text="[20]">
<p style="padding-top: 6pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark20"></a>&zwnj;Yinlin Deng, Chunqiu Steven Xia, Haoran Peng, Chenyuan Yang, and Lingming Zhang. Large language models are zero-shot fuzzers: Fuzzing deep-learning libraries via large language models. In Ren&eacute; Just and Gordon Fraser, editors, <span class="s32">32nd ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2023, Seattle, WA, USA, July 17-21, 2023</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3597926.3598067" target="_blank" rel="noopener">, pages 423&ndash;435. ACM, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3597926.3598067</span>.</p>
</li>
<li data-list-text="[21]">
<p style="padding-top: 6pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark21"></a>&zwnj;Yinlin Deng, Chunqiu Steven Xia, Chenyuan Yang, Shizhuo Dylan Zhang, Shujing Yang, and Lingming Zhang. Large language models are edge-case generators: Crafting unusual programs for fuzzing deep learning libraries. In <span class="s32">46th IEEE/ACM International Conference on Software Engineering, ICSE 2024, Lisbon, Portugal, April 14-20, 2024</span>, pages 70:1&ndash;70:13.&nbsp;<a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3597503.3623343" target="_blank" rel="noopener">ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3597503.3623343</span>.</p>
</li>
<li data-list-text="[22]">
<p style="padding-top: 7pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2405.03709" target="_blank" rel="noopener" name="bookmark22">Karim Elmaaroufi, Devan Shanker, Ana Cismaru, Marcell Vazquez-Chanlatte, Alberto Sangiovanni-Vincentelli, Matei Zaharia, and Sanjit A. Seshia. Generating probabilistic scenario programs from natural language, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2405.03709</span>.</p>
</li>
<li data-list-text="[23]">
<p style="padding-top: 6pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark23"></a>&zwnj;Madeline Endres, Sarah Fakhoury, Saikat Chakraborty, and Shuvendu K. Lahiri. Can large language models transform natural language intent into formal method postconditions? <span class="s32">Proc. ACM Softw. Eng.</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3660791" target="_blank" rel="noopener">, 1(FSE):1889&ndash;1912, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3660791</span>.</p>
</li>
<li data-list-text="[24]">
<p style="padding-top: 6pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark24"></a>&zwnj;Sidong Feng and Chunyang Chen. Prompting is all you need: Automated android bug replay with large language models. In <span class="s32">46th IEEE/ACM International Conference on Software Engineering, ICSE 2024, Lisbon, Portugal, April 14-20, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3597503.3608137" target="_blank" rel="noopener">, pages 67:1&ndash;67:13. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3597503.3608137</span>.</p>
</li>
<li data-list-text="[25]">
<p style="padding-top: 6pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark25"></a>&zwnj;Michael Fu, Chakkrit Kla Tantithamthavorn, Van Nguyen, and Trung Le. ChatGPT for vulnerability detection, classification, and repair: How far are we? In <span class="s32">30th Asia-Pacific Software Engineering Conference, APSEC 2023, Seoul, Republic of Korea, December 4-7, 2023</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1109/APSEC60848.2023.00085" target="_blank" rel="noopener">, pages 632&ndash;636. IEEE, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1109/APSEC60848.2023.00085</span>.</p>
<p style="padding-top: 3pt; text-indent: 0pt; text-align: left;">&nbsp;</p>
</li>
<li data-list-text="[26]">
<p style="padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2311.12420" target="_blank" rel="noopener" name="bookmark26"> Zeyu Gao, Hao Wang, Yuchen Zhou, Wenyu Zhu, and Chao Zhang. How far have we gone in vulnerability detection using large language models, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2311.12420</span>.</p>
</li>
<li data-list-text="[27]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark27"></a>&zwnj;Drishti Goel, Fiza Husain, Aditya Singh, Supriyo Ghosh, Anjaly Parayil, Chetan Bansal, Xuchao Zhang, and Saravan Rajmohan. X-lifecycle learning for cloud incident management using LLMs. In Marcelo d&rsquo;Amorim, editor, <span class="s32">Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering, FSE 2024, Porto de Galinhas, Brazil, July 15-19, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3663529.3663861" target="_blank" rel="noopener">, pages 417&ndash;428. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3663529.3663861</span>.</p>
</li>
<li data-list-text="[28]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a name="bookmark28"></a>&zwnj;Google. AI-powered fuzzing: Breaking the bug hunting barrier, 2023. At security.googleblog.com [accessed April 2024].</p>
</li>
<li data-list-text="[29]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2312.08477" target="_blank" rel="noopener" name="bookmark29">Yu Hao, Weiteng Chen, Ziqiao Zhou, and Weidong Cui. E&amp;V: Prompting large language models to perform static analysis by pseudo-code execution and verification, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2312.08477</span>.</p>
</li>
<li data-list-text="[30]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark30"></a>&zwnj;Andreas Happe and Ju&uml;rgen Cito. Getting pwn&rsquo;d by AI: Penetration testing with large language models. In Satish Chandra, Kelly Blincoe, and Paolo Tonella, editors, <span class="s32">31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2023, San Francisco, CA, USA, December 3-9, 2023</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3611643.3613083" target="_blank" rel="noopener">, pages 2082&ndash;2086. ACM, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3611643.3613083</span>.</p>
</li>
<li data-list-text="[31]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2405.03786" target="_blank" rel="noopener" name="bookmark31"> Soneya Binta Hossain and Matthew Dwyer. TOGLL: Correct and strong test oracle generation with LLMs, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2405.03786</span>.</p>
</li>
<li data-list-text="[32]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: left;"><a name="bookmark32"></a>&zwnj;Jie Hu, Qian Zhang, and Heng Yin. Augmenting greybox fuzzing with generative AI, 2023,</p>
<p style="padding-left: 31pt; text-indent: 0pt; text-align: left;"><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2306.06782</span>.</p>
</li>
<li data-list-text="[33]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark33"></a>&zwnj;Sihao Hu, Tiansheng Huang, Fatih Ilhan, Selim Furkan Tekin, and Ling Liu. Large language model-powered smart contract vulnerability detection: New perspectives. In <span class="s32">5th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications, TPS-ISA 2023, Atlanta, GA, USA, November 1-4, 2023</span>, pages 297&ndash;306. IEEE,</p>
<p style="padding-left: 31pt; text-indent: 0pt; line-height: 12pt; text-align: left;"><a style="color: black; text-decoration: none;" href="https://doi.org/10.1109/TPS-ISA58951.2023.00044" target="_blank" rel="noopener">2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1109/TPS-ISA58951.2023.00044</span>.</p>
</li>
<li data-list-text="[34]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2308.08784" target="_blank" rel="noopener" name="bookmark34">Dong Huang, Qingwen Bu, Yuhao Qing, and Heming Cui. CodeCoT: Tackling code syntax errors in CoT reasoning for code generation, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2308.08784</span>.</p>
</li>
<li data-list-text="[35]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2312.13010" target="_blank" rel="noopener" name="bookmark35">Dong Huang, Qingwen Bu, Jie M. Zhang, Michael Luck, and Heming Cui. AgentCoder: Multi-agent-based code generation with iterative testing and optimisation, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2312.13010</span>.</p>
</li>
<li data-list-text="[36]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2306.00757" target="_blank" rel="noopener" name="bookmark36">Qing Huang, Zhou Zou, Zhenchang Xing, Zhenkang Zuo, Xiwei Xu, and Qinghua Lu. AI chain on large language model for unsupervised control flow graph generation for statically-typed partial code, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2306.00757</span>.</p>
</li>
<li data-list-text="[37]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark37"></a>&zwnj;Yuchao Huang, Junjie Wang, Zhe Liu, Yawen Wang, Song Wang, Chunyang Chen, Yuanzhe Hu, and Qing Wang. CrashTranslator: Automatically reproducing mobile application crashes directly from stack trace. In <span class="s32">46th IEEE/ACM International Conference on Software Engineering, ICSE 2024, Lisbon, Portugal, April 14-20, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3597503.3623298" target="_blank" rel="noopener">, pages 18:1&ndash;18:13. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3597503.3623298</span>.</p>
</li>
<li data-list-text="[38]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2310.02407" target="_blank" rel="noopener" name="bookmark38">Ali Reza Ibrahimzada, Yang Chen, Ryan Rong, and Reyhaneh Jabbarvand. Automated bug generation in the era of large language models, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2310.02407</span>.</p>
</li>
<li data-list-text="[39]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2404.03664" target="_blank" rel="noopener" name="bookmark39"> Erblin Isaku, Christoph Laaber, Hassan Sartaj, Shaukat Ali, Thomas Schwitalla, and Jan F. Nyg˚ard. LLMs in the heart of differential testing: A case study on a medical rule engine, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2404.03664</span>.</p>
<p style="padding-top: 3pt; text-indent: 0pt; text-align: left;">&nbsp;</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
</li>
<li data-list-text="[40]">
<p style="padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark40"></a>&zwnj;Christian Jan&szlig;en, Cedric Richter, and Heike Wehrheim. Can ChatGPT support software verification? In Dirk Beyer and Ana Cavalcanti, editors, <span class="s32">Fundamental Approaches to Software Engineering - 27th International Conference, FASE 2024, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2024, Luxembourg City, Luxembourg, April 6-11, 2024, Proceedings</span>, volume 14573 of <span class="s32">Lecture Notes in Computer Science</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1007/978-3-031-57259-3_13" target="_blank" rel="noopener">, pages 266&ndash;279. Springer, 2024,&nbsp;</a><a class="a" href="https://doi.org/10.1007/978-3-031-57259-3_13" target="_blank" rel="noopener">doi:10.1007/978-3-031-57259-3&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">13</span>.</p>
</li>
<li data-list-text="[41]">
<p style="padding-top: 8pt; padding-left: 29pt; text-indent: -18pt; text-align: justify;"><a name="bookmark41"></a>&zwnj;Rasmus Ingemann Tuffveson Jensen, Vali Tawosi, and Salwa Alamir. Software vulnerability and functionality assessment using large language models. In Maliheh Izadi, Andrea Di Sorbo, and Sebastiano Panichella, editors, <span class="s32">Proceedings of the Third ACM/IEEE International Workshop on NL-based Software Engineering, NLBSE 2024, Lisbon, Portugal, 20 April 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3643787.3648036" target="_blank" rel="noopener">, pages 25&ndash;28. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3643787.3648036</span>.</p>
</li>
<li data-list-text="[42]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2312.06875" target="_blank" rel="noopener" name="bookmark42"> Siva Kesava Reddy Kakarla and Ryan Beckett. Oracle-based protocol testing with Eywa, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2312.06875</span>.</p>
</li>
<li data-list-text="[43]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2311.07948" target="_blank" rel="noopener" name="bookmark43"> Adharsh Kamath, Aditya Senthilnathan, Saikat Chakraborty, Pantazis Deligiannis, Shuvendu K. Lahiri, Akash Lal, Aseem Rastogi, Subhajit Roy, and Rahul Sharma. Finding inductive loop invariants using large language models, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2311.07948</span>.</p>
</li>
<li data-list-text="[44]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a name="bookmark44"></a>&zwnj;Sungmin Kang, Gabin An, and Shin Yoo. A quantitative and qualitative evaluation of LLM-based explainable fault localization. <span class="s32">Proc. ACM Softw. Eng.</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3660771" target="_blank" rel="noopener">, 1(FSE):1424&ndash;1446, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3660771</span>.</p>
</li>
<li data-list-text="[45]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2304.02195" target="_blank" rel="noopener" name="bookmark45"> Sungmin Kang, Bei Chen, Shin Yoo, and Jian-Guang Lou. Explainable automated debugging via large language model-driven scientific debugging, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2304.02195</span>.</p>
</li>
<li data-list-text="[46]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark46"></a>&zwnj;Sungmin Kang, Juyeon Yoon, and Shin Yoo. Large language models are few-shot testers: Exploring LLM-based general bug reproduction. In <span class="s32">45th IEEE/ACM International Conference on Software Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023</span>, pages 2312&ndash;</p>
<p style="padding-left: 31pt; text-indent: 0pt; text-align: left;"><a style="color: black; text-decoration: none;" href="https://doi.org/10.1109/ICSE48619.2023.00194" target="_blank" rel="noopener">2323. IEEE, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1109/ICSE48619.2023.00194</span>.</p>
</li>
<li data-list-text="[47]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2301.03543" target="_blank" rel="noopener" name="bookmark47">Ahmed Khanfir, Renzo Degiovanni, Mike Papadakis, and Yves Le Traon. Efficient mutation testing via pre-trained language models, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2301.03543</span>.</p>
</li>
<li data-list-text="[48]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2311.16169" target="_blank" rel="noopener" name="bookmark48"> Avishree Khare, Saikat Dutta, Ziyang Li, Alaia Solko-Breslin, Rajeev Alur, and Mayur Naik. Understanding the effectiveness of large language models in detecting security vulnerabilities, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2311.16169</span>.</p>
</li>
<li data-list-text="[49]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark49"></a>&zwnj;Myeongsoo Kim, Tyler Stennett, Dhruv Shah, Saurabh Sinha, and Alessandro Orso. Leveraging large language models to improve REST API testing. In <span class="s32">Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results, NIER@ICSE 2024, Lisbon, Portugal, April 14-20, 2024</span>, pages 37&ndash;41. ACM,</p>
<p style="padding-left: 31pt; text-indent: 0pt; line-height: 12pt; text-align: left;"><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3639476.3639769" target="_blank" rel="noopener">2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3639476.3639769</span>.</p>
</li>
<li data-list-text="[50]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark50"></a>&zwnj;Caroline Lemieux, Jeevana Priya Inala, Shuvendu K. Lahiri, and Siddhartha Sen. CodaMOSA: Escaping coverage plateaus in test generation with pre-trained large language models. In <span class="s32">45th IEEE/ACM International Conference on Software Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1109/ICSE48619.2023.00085" target="_blank" rel="noopener">, pages 919&ndash;931. IEEE, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1109/ICSE48619.2023.00085</span>.</p>
</li>
<li data-list-text="[51]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a name="bookmark51"></a>&zwnj;Haonan Li, Yu Hao, Yizhuo Zhai, and Zhiyun Qian. Enhancing static analysis for practical bug detection: An LLM-integrated approach. <span class="s32">Proc. ACM Program. Lang.</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3649828" target="_blank" rel="noopener">, 8(OOPSLA1):474&ndash;499, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3649828</span>.</p>
</li>
<li data-list-text="[52]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2404.13340" target="_blank" rel="noopener" name="bookmark52">Kefan Li and Yuan Yuan. Large language models as test case generators: Performance evaluation and enhancement, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2404.13340</span>.</p>
<p style="padding-top: 3pt; text-indent: 0pt; text-align: left;">&nbsp;</p>
</li>
<li data-list-text="[53]">
<p style="padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark53"></a>&zwnj;Tsz-On Li, Wenxi Zong, Yibo Wang, Haoye Tian, Ying Wang, Shing-Chi Cheung, and Jeff Kramer. Nuances are the key: Unlocking ChatGPT to find failure-inducing tests with differential prompting. In <span class="s32">38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023, Kirchberg, Luxembourg, September 11-15, 2023</span>, pages 1:1&ndash;1:13.</p>
<p style="padding-left: 31pt; text-indent: 0pt; line-height: 12pt; text-align: left;"><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3551349.3560420" target="_blank" rel="noopener">ACM, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3551349.3560420</span>.</p>
</li>
<li data-list-text="[54]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2404.10304" target="_blank" rel="noopener" name="bookmark54">Kaibo Liu, Yiyang Liu, Zhenpeng Chen, Jie M. Zhang, Yudong Han, Yun Ma, Ge Li, and Gang Huang. LLM-powered test case generation for detecting tricky bugs, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2404.10304</span>.</p>
</li>
<li data-list-text="[55]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2310.08275" target="_blank" rel="noopener" name="bookmark55">Puzhuo Liu, Chengnian Sun, Yaowen Zheng, Xuan Feng, Chuan Qin, Yuncheng Wang, Zhi Li, and Limin Sun. Harnessing the power of LLM to support binary taint analysis,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2310.08275</span>.</p>
</li>
<li data-list-text="[56]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2405.02580" target="_blank" rel="noopener" name="bookmark56">Ye Liu, Yue Xue, Daoyuan Wu, Yuqiang Sun, Yi Li, Miaolei Shi, and Yang Liu. PropertyGPT: LLM-driven formal verification of smart contracts through retrieval-augmented property generation, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2405.02580</span>.</p>
</li>
<li data-list-text="[57]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark57"></a>&zwnj;Zhe Liu, Chunyang Chen, Junjie Wang, Xing Che, Yuekai Huang, Jun Hu, and Qing Wang. Fill in the blank: Context-aware automated text input generation for mobile GUI testing. In <span class="s32">45th IEEE/ACM International Conference on Software Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1109/ICSE48619.2023.00119" target="_blank" rel="noopener">, pages 1355&ndash;1367. IEEE, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1109/ICSE48619.2023.00119</span>.</p>
</li>
<li data-list-text="[58]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -20pt; text-align: justify;"><a name="bookmark58"></a>&zwnj;Zhe Liu, Chunyang Chen, Junjie Wang, Mengzhuo Chen, Boyu Wu, Xing Che, Dandan Wang, and Qing Wang. Make LLM a testing expert: Bringing human-like interaction to mobile GUI testing via functionality-aware decisions. In <span class="s32">46th IEEE/ACM International Conference on Software Engineering, ICSE 2024, Lisbon, Portugal, April 14-20, 2024</span>, pages 100:1&ndash;100:13.</p>
<p style="padding-left: 31pt; text-indent: 0pt; line-height: 12pt; text-align: left;"><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3597503.3639180" target="_blank" rel="noopener">ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3597503.3639180</span>.</p>
</li>
<li data-list-text="[59]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark59"></a>&zwnj;Zhe Liu, Chunyang Chen, Junjie Wang, Mengzhuo Chen, Boyu Wu, Zhilin Tian, Yuekai Huang, Jun Hu, and Qing Wang. Testing the limits: Unusual text inputs generation for mobile app crash detection with large language model. In <span class="s32">46th IEEE/ACM International Conference on Software Engineering, ICSE 2024, Lisbon, Portugal, April 14-20, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3597503.3639118" target="_blank" rel="noopener">, pages 137:1&ndash;137:12. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3597503.3639118</span>.</p>
</li>
<li data-list-text="[60]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -20pt; text-align: justify;"><a name="bookmark60"></a>&zwnj;Guilong Lu, Xiaolin Ju, Xiang Chen, Wenlong Pei, and Zhilong Cai. GRACE: Empowering LLM-based software vulnerability detection with graph structure and in-context learning. <span class="s32">J. Syst. Softw.</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1016/J.JSS.2024.112031" target="_blank" rel="noopener">, 212:112031, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1016/J.JSS.2024.112031</span>.</p>
</li>
<li data-list-text="[61]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a name="bookmark61"></a>&zwnj;Dipeeka Luitel, Shiva Nejati, and Mehrdad Sabetzadeh. Requirements-driven slicing of Simulink models using LLMs. In <span class="s32">32nd IEEE International Requirements Engineering Conference, RE 2024 - Workshops, Reykjavik, Iceland, June 24-25, 2024</span>, pages 72&ndash;82. IEEE,</p>
<p style="padding-left: 31pt; text-indent: 0pt; text-align: left;"><a style="color: black; text-decoration: none;" href="https://doi.org/10.1109/REW61692.2024.00014" target="_blank" rel="noopener">2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1109/REW61692.2024.00014</span>.</p>
</li>
<li data-list-text="[62]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2401.08807" target="_blank" rel="noopener" name="bookmark62">Lezhi Ma, Shangqing Liu, Yi Li, Xiaofei Xie, and Lei Bu. SpecGen: Automated generation of formal program specifications via large language models, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2401.08807</span>.</p>
</li>
<li data-list-text="[63]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark63"></a>&zwnj;Ruijie Meng, Martin Mirchev, Marcel B&uml;ohme, and Abhik Roychoudhury. Large language model guided protocol fuzzing. In <span class="s32">Network and Distributed System Security (NDSS) Symposium 2024, 26 February - 1 March 2024, San Diego, CA, USA</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.14722/ndss.2024.24556" target="_blank" rel="noopener">, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.14722/ndss.2024.24556</span>.</p>
</li>
<li data-list-text="[64]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a name="bookmark64"></a>&zwnj;Md Rakib Hossain Misu, Cristina V. Lopes, Iris Ma, and James Noble. Towards AI-assisted synthesis of verified Dafny methods. <span class="s32">Proc. ACM Softw. Eng.</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3643763" target="_blank" rel="noopener">, 1(FSE):812&ndash;835, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3643763</span>.</p>
<p style="padding-top: 3pt; text-indent: 0pt; text-align: left;">&nbsp;</p>
</li>
<li data-list-text="[65]">
<p style="padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark65"></a>&zwnj;Mohammad Mahdi Mohajer, Reem Aleithan, Nima Shiri Harzevili, Moshi Wei, Alvine Boaye Belle, Hung Viet Pham, and Song Wang. Effectiveness of ChatGPT for static analysis: How far are we? In Bram Adams, Thomas Zimmermann, Ipek Ozkaya, Dayi Lin, and Jie M. Zhang, editors, <span class="s32">Proceedings of the 1st ACM International Conference on AI-Powered Software, AIware 2024, Porto de Galinhas, Brazil, July 15-16, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3664646.3664777" target="_blank" rel="noopener">. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3664646.3664777</span>.</p>
</li>
<li data-list-text="[66]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a name="bookmark66"></a>&zwnj;Fangwen Mu, Lin Shi, Song Wang, Zhuohao Yu, Binquan Zhang, Chenxue Wang, Shichao Liu, and Qing Wang. ClarifyGPT: A framework for enhancing LLM-based code generation via requirements clarification. <span class="s32">Proc. ACM Softw. Eng.</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3660810" target="_blank" rel="noopener">, 1(FSE):2332&ndash;2354, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3660810</span>.</p>
</li>
<li data-list-text="[67]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark67"></a>&zwnj;Noor Nashid, Mifta Sintaha, and Ali Mesbah. Retrieval-based prompt selection for code-related few-shot learning. In <span class="s32">45th IEEE/ACM International Conference on Software Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1109/ICSE48619.2023.00205" target="_blank" rel="noopener">, pages 2450&ndash;2462. IEEE, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1109/ICSE48619.2023.00205</span>.</p>
</li>
<li data-list-text="[68]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2402.17230" target="_blank" rel="noopener" name="bookmark68"> Yu Nong, Mohammed Aldeen, Long Cheng, Hongxin Hu, Feng Chen, and Haipeng Cai. Chain-of-thought prompting of large language models for discovering and fixing software vulnerabilities, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2402.17230</span>.</p>
</li>
<li data-list-text="[69]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2403.16218" target="_blank" rel="noopener" name="bookmark69">Juan Altmayer Pizzorno and Emery D. Berger. CoverUp: Coverage-guided LLM-based test generation, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2403.16218</span>.</p>
</li>
<li data-list-text="[70]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark70"></a>&zwnj;Feng Qiu, Pu Ji, Baojian Hua, and Yang Wang. CHEMFUZZ: large language models-assisted fuzzing for quantum chemistry software bug detection. In <span class="s32">23rd IEEE International Conference on Software Quality, Reliability, and Security, QRS 2023 Companion, Chiang Mai, Thailand, October 22-26, 2023</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1109/QRS-C60940.2023.00104" target="_blank" rel="noopener">, pages 103&ndash;112. IEEE, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1109/QRS-C60940.2023.00104</span>.</p>
</li>
<li data-list-text="[71]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark71"></a>&zwnj;Devjeet Roy, Xuchao Zhang, Rashi Bhave, Chetan Bansal, Pedro Henrique B. Las-Casas, Rodrigo Fonseca, and Saravan Rajmohan. Exploring LLM-based agents for root cause analysis. In Marcelo d&rsquo;Amorim, editor, <span class="s32">Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering, FSE 2024, Porto de Galinhas, Brazil, July 15-19, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3663529.3663841" target="_blank" rel="noopener">, pages 208&ndash;219. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3663529.3663841</span>.</p>
</li>
<li data-list-text="[72]">
<p style="padding-top: 7pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a name="bookmark72"></a>&zwnj;Gabriel Ryan, Siddhartha Jain, Mingyue Shang, Shiqi Wang, Xiaofei Ma, Murali Krishna Ramanathan, and Baishakhi Ray. Code-aware prompting: A study of coverage-guided test generation in regression setting using LLM. <span class="s32">Proc. ACM Softw. Eng.</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3643769" target="_blank" rel="noopener">, 1(FSE):951&ndash;971, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3643769</span>.</p>
</li>
<li data-list-text="[73]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a name="bookmark73"></a>&zwnj;Max Sch&uml;afer, Sarah Nadi, Aryaz Eghbali, and Frank Tip. An empirical evaluation of using large language models for automated unit test generation. <span class="s32">IEEE Trans. Software Eng.</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1109/TSE.2023.3334955" target="_blank" rel="noopener">, 50(1):85&ndash;105, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1109/TSE.2023.3334955</span>.</p>
</li>
<li data-list-text="[74]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark74"></a>&zwnj;Prakhar Sharma and Vinod Yegneswaran. PROSPER: Extracting protocol specifications using large language models. In <span class="s32">Proceedings of the 22nd ACM Workshop on Hot Topics in Networks, HotNets 2023, Cambridge, MA, USA, November 28-29, 2023</span>, pages 41&ndash;47. ACM,</p>
<p style="padding-left: 31pt; text-indent: 0pt; text-align: left;"><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3626111.3628205" target="_blank" rel="noopener">2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3626111.3628205</span>.</p>
</li>
<li data-list-text="[75]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: left;"><a name="bookmark75"></a>&zwnj;Kumar Shashwat, Francis Hahn, Xinming Ou, Dmitry Goldgof, Lawrence Hall, Jay Ligatti,</p>
<p style="padding-left: 31pt; text-indent: 0pt; text-align: left;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2401.17459" target="_blank" rel="noopener">S. Raj Rajgopalan, and Armin Ziaie Tabari. A preliminary study on using large language models in software pentesting, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2401.17459</span>.</p>
</li>
<li data-list-text="[76]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2401.17019" target="_blank" rel="noopener" name="bookmark76"> Seung Yeob Shin, Fabrizio Pastore, Domenico Bianculli, and Alexandra Baicoianu. Towards generating executable metamorphic relations using large language models, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2401.17019</span>.</p>
<p style="padding-top: 3pt; text-indent: 0pt; text-align: left;">&nbsp;</p>
</li>
<li data-list-text="[77]">
<p style="padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark77"></a>&zwnj;Mohammed Latif Siddiq, Joanna Cecilia da Silva Santos, Ridwanul Hasan Tanvir, Noshin Ulfat, Fahmid Al Rifat, and Vinicius Carvalho Lopes. Using large language models to generate JUnit tests: An empirical study. In <span class="s32">Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering, EASE 2024, Salerno, Italy, June 18-21, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3661167.3661216" target="_blank" rel="noopener">, pages 313&ndash;322. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3661167.3661216</span>.</p>
</li>
<li data-list-text="[78]">
<p style="padding-top: 7pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark78"></a>&zwnj;Yanqi Su, Dianshu Liao, Zhenchang Xing, Qing Huang, Mulong Xie, Qinghua Lu, and Xiwei Xu. Enhancing exploratory testing by large language model and knowledge graph. In <span class="s32">46th IEEE/ACM International Conference on Software Engineering, ICSE 2024, Lisbon, Portugal, April 14-20, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3597503.3639157" target="_blank" rel="noopener">, pages 98:1&ndash;98:12. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3597503.3639157</span>.</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
</li>
<li data-list-text="[79]">
<p style="padding-top: 7pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark79"></a>&zwnj;Chuyue Sun, Ying Sheng, Oded Padon, and Clark W. Barrett. Clover: Closed-loop verifiable code generation. In Guy Avni, Mirco Giacobbe, Taylor T. Johnson, Guy Katz, Anna Lukina, Nina Narodytska, and Christian Schilling, editors, <span class="s32">AI Verification - First International Symposium, SAIV 2024, Montreal, QC, Canada, July 22-23, 2024, Proceedings</span>, volume 14846 of <span class="s32">Lecture Notes in Computer Science</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1007/978-3-031-65112-0_7" target="_blank" rel="noopener">, pages 134&ndash;155. Springer, 2024,&nbsp;</a><a class="a" href="https://doi.org/10.1007/978-3-031-65112-0_7" target="_blank" rel="noopener">doi:10.1007/978-3-031-65112-0&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">7</span>.</p>
</li>
<li data-list-text="[80]">
<p style="padding-top: 7pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2401.16185" target="_blank" rel="noopener" name="bookmark80"> Yuqiang Sun, Daoyuan Wu, Yue Xue, Han Liu, Wei Ma, Lyuye Zhang, Miaolei Shi, and Yang Liu. LLM4Vuln: A unified evaluation framework for decoupling and enhancing LLMs&rsquo; vulnerability reasoning, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2401.16185</span>.</p>
</li>
<li data-list-text="[81]">
<p style="padding-top: 7pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark81"></a>&zwnj;Yuqiang Sun, Daoyuan Wu, Yue Xue, Han Liu, Haijun Wang, Zhengzi Xu, Xiaofei Xie, and Yang Liu. GPTScan: Detecting logic vulnerabilities in smart contracts by combining GPT with program analysis. In <span class="s32">46th IEEE/ACM International Conference on Software Engineering, ICSE 2024, Lisbon, Portugal, April 14-20, 2024</span>, pages 166:1&ndash;166:13. ACM,</p>
<p style="padding-left: 31pt; text-indent: 0pt; line-height: 12pt; text-align: left;"><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3597503.3639117" target="_blank" rel="noopener">2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3597503.3639117</span>.</p>
</li>
<li data-list-text="[82]">
<p style="padding-top: 7pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark82"></a>&zwnj;Maryam Taeb, Amanda Swearngin, Eldon Schoop, Ruijia Cheng, Yue Jiang, and Jeffrey Nichols. AXNav: Replaying accessibility tests from natural language. In Florian &rsquo;Floyd&rsquo; Mueller, Penny Kyburz, Julie R. Williamson, Corina Sas, Max L. Wilson, Phoebe O. Toups Dugas, and Irina Shklovski, editors, <span class="s32">Proceedings of the CHI Conference on Human Factors in Computing Systems, CHI 2024, Honolulu, HI, USA, May 11-16, 2024</span>, pages 962:1&ndash;962:16.</p>
<p style="padding-left: 31pt; text-indent: 0pt; line-height: 11pt; text-align: left;"><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3613904.3642777" target="_blank" rel="noopener">ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3613904.3642777</span>.</p>
</li>
<li data-list-text="[83]">
<p style="padding-top: 7pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2210.02506" target="_blank" rel="noopener" name="bookmark83">Mohammad Reza Taesiri, Finlay Macklon, Yihe Wang, Hengshuo Shen, and Cor-Paul Bezemer. Large language models are pretty good zero-shot video game bug detectors, 2022,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2210.02506</span>.</p>
</li>
<li data-list-text="[84]">
<p style="padding-top: 7pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark84"></a>&zwnj;Norbert Tihanyi, Tam&aacute;s Bisztray, Ridhi Jain, Mohamed Amine Ferrag, Lucas C. Cordeiro, and Vasileios Mavroeidis. The FormAI dataset: Generative AI in software security through the lens of formal verification. In Shane McIntosh, Eunjong Choi, and Steffen Herbold, editors, <span class="s32">Proceedings of the 19th International Conference on Predictive Models and Data Analytics in Software Engineering, PROMISE 2023, San Francisco, CA, USA, 8 December 2023</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3617555.3617874" target="_blank" rel="noopener">, pages 33&ndash;43. ACM, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3617555.3617874</span>.</p>
</li>
<li data-list-text="[85]">
<p style="padding-top: 7pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2404.09952" target="_blank" rel="noopener" name="bookmark85">Frank Tip, Jonathan Bell, and Max Sch&uml;afer. LLMorpheus: Mutation testing using large language models, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2404.09952</span>.</p>
</li>
<li data-list-text="[86]">
<p style="padding-top: 7pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark86"></a>&zwnj;Christos Tsigkanos, Pooja Rani, Sebastian Mu&uml;ller, and Timo Kehrer. Large language models: The next frontier for variable discovery within metamorphic testing? In Tao Zhang, Xin Xia, and Nicole Novielli, editors, <span class="s32">IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023, Taipa, Macao, March 21-24, 2023</span>, pages 678&ndash;682. IEEE,</p>
<p style="padding-left: 31pt; text-indent: 0pt; line-height: 12pt; text-align: left;"><a style="color: black; text-decoration: none;" href="https://doi.org/10.1109/SANER56733.2023.00070" target="_blank" rel="noopener">2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1109/SANER56733.2023.00070</span>.</p>
</li>
<li data-list-text="[87]">
<p style="padding-top: 7pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark87"></a>&zwnj;Haoxin Tu, Zhide Zhou, He Jiang, Imam Nur Bani Yusuf, Yuxian Li, and Lingxiao Jiang. Isolating compiler bugs by generating effective witness programs with large language models. <span class="s32">IEEE Trans. Software Eng.</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1109/TSE.2024.3397822" target="_blank" rel="noopener">, 50(7):1768&ndash;1788, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1109/TSE.2024.3397822</span>.</p>
<p style="padding-top: 3pt; text-indent: 0pt; text-align: left;">&nbsp;</p>
</li>
<li data-list-text="[88]">
<p style="padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2307.04346" target="_blank" rel="noopener" name="bookmark88">Vasudev Vikram, Caroline Lemieux, and Rohan Padhye. Can large language models write good property-based tests?, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2307.04346</span>.</p>
</li>
<li data-list-text="[89]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a name="bookmark89"></a>&zwnj;Nalin Wadhwa, Jui Pradhan, Atharv Sonwane, Surya Prakash Sahu, Nagarajan Natarajan, Aditya Kanade, Suresh Parthasarathy, and Sriram Rajamani. CORE: Resolving code quality issues using LLMs. <span class="s32">Proc. ACM Softw. Eng.</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3643762" target="_blank" rel="noopener">, 1(FSE):789&ndash;811, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3643762</span>.</p>
</li>
<li data-list-text="[90]">
<p style="padding-top: 7pt; padding-left: 30pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2402.10754" target="_blank" rel="noopener" name="bookmark90"> Chengpeng Wang, Wuqi Zhang, Zian Su, Xiangzhe Xu, Xiaoheng Xie, and Xiangyu Zhang. When dataflow analysis meets large language models, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2402.10754</span>.</p>
</li>
<li data-list-text="[91]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2311.04448" target="_blank" rel="noopener" name="bookmark91">Chong Wang, Jianan Liu, Xin Peng, Yang Liu, and Yiling Lou. Inferring resource-oriented intentions using LLMs for static resource leak detection, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2311.04448</span>.</p>
</li>
<li data-list-text="[92]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark92"></a>&zwnj;Moshi Wei, Nima Shiri Harzevili, Yuekai Huang, Jinqiu Yang, Junjie Wang, and Song Wang. Demystifying and detecting misuses of deep learning APIs. In <span class="s32">46th IEEE/ACM International Conference on Software Engineering, ICSE 2024, Lisbon, Portugal, April 14-20, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3597503.3639177" target="_blank" rel="noopener">, pages 201:1&ndash;201:12. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3597503.3639177</span>.</p>
<p style="text-indent: 0pt; text-align: left;">&nbsp;</p>
</li>
<li data-list-text="[93]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark93"></a>&zwnj;Cheng Wen, Jialun Cao, Jie Su, Zhiwu Xu, Shengchao Qin, Mengda He, Haokun Li, Shing-Chi Cheung, and Cong Tian. Enchanting program specification synthesis by large language models using static analysis and program verification. In Arie Gurfinkel and Vijay Ganesh, editors, <span class="s32">Computer Aided Verification - 36th International Conference, CAV 2024, Montreal, QC, Canada, July 24-27, 2024, Proceedings, Part II</span>, volume 14682 of <span class="s32">Lecture Notes in Computer Science</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1007/978-3-031-65630-9_16" target="_blank" rel="noopener">, pages 302&ndash;328. Springer, 2024,&nbsp;</a><a class="a" href="https://doi.org/10.1007/978-3-031-65630-9_16" target="_blank" rel="noopener">doi:10.1007/978-3-031-65630-9&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">16</span>.</p>
</li>
<li data-list-text="[94]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark94"></a>&zwnj;Haoze Wu, Clark Barrett, and Nina Narodytska. Lemur: Integrating large language models in automated program verification. In <span class="s32">The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11 2024</span>. OpenReview.net, 2024.</p>
</li>
<li data-list-text="[95]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark95"></a>&zwnj;Shengnan Wu, Yongxiang Hu, Yingchuan Wang, Jiazhen Gu, Jin Meng, Liujie Fan, Zhongshi Luan, Xin Wang, and Yangfan Zhou. Combating missed recalls in e-commerce search: A CoT-prompting testing approach. In Marcelo d&rsquo;Amorim, editor, <span class="s32">Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering, FSE 2024, Porto de Galinhas, Brazil, July 15-19, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3663529.3663842" target="_blank" rel="noopener">, pages 220&ndash;231. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3663529.3663842</span>.</p>
</li>
<li data-list-text="[96]">
<p style="padding-top: 7pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2308.15276" target="_blank" rel="noopener" name="bookmark96">Yonghao Wu, Zheng Li, Jie M. Zhang, Mike Papadakis, Mark Harman, and Yong Liu. Large language models in fault localisation, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2308.15276</span>.</p>
</li>
<li data-list-text="[97]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -19pt; text-align: justify;"><a name="bookmark97"></a>&zwnj;Chunqiu Steven Xia, Matteo Paltenghi, Jia Le Tian, Michael Pradel, and Lingming Zhang. Fuzz4All: Universal fuzzing with large language models. In <span class="s32">46th IEEE/ACM International Conference on Software Engineering, ICSE 2024, Lisbon, Portugal, April 14-20, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3597503.3639121" target="_blank" rel="noopener">, pages 126:1&ndash;126:13. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3597503.3639121</span>.</p>
</li>
<li data-list-text="[98]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2404.04966" target="_blank" rel="noopener" name="bookmark98">Chen Yang, Junjie Chen, Bin Lin, Jianyi Zhou, and Ziqi Wang. Enhancing LLM-based test generation for hard-to-cover branches via program analysis, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2404.04966</span>.</p>
</li>
<li data-list-text="[99]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -20pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2310.15991" target="_blank" rel="noopener" name="bookmark99">Chenyuan Yang, Yinlin Deng, Runyu Lu, Jiayi Yao, Jiawei Liu, Reyhaneh Jabbarvand, and Lingming Zhang. White-box compiler fuzzing empowered by large language models, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2310.15991</span>.</p>
</li>
<li data-list-text="[100]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -25pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2401.00563" target="_blank" rel="noopener" name="bookmark100">Chenyuan Yang, Zijie Zhao, and Lingming Zhang. KernelGPT: enhanced kernel fuzzing via large language models, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2401.00563</span>.</p>
</li>
<li data-list-text="[101]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -25pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2405.01202" target="_blank" rel="noopener" name="bookmark101">Yanjing Yang, Xin Zhou, Runfeng Mao, Jinwei Xu, Lanxin Yang, Yu Zhangm, Haifeng Shen, and He Zhang. DLAP: A deep learning augmented large language model prompting framework for software vulnerability detection, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2405.01202</span>.</p>
<p style="padding-top: 3pt; text-indent: 0pt; text-align: left;">&nbsp;</p>
</li>
<li data-list-text="[102]">
<p style="padding-left: 31pt; text-indent: -25pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2311.03739" target="_blank" rel="noopener" name="bookmark102">Jianan Yao, Ziqiao Zhou, Weiteng Chen, and Weidong Cui. Leveraging large language models for automated proof synthesis in Rust, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2311.03739</span>.</p>
</li>
<li data-list-text="[103]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -25pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2404.02056" target="_blank" rel="noopener" name="bookmark103">Xin Yin, Chao Ni, and Shaohua Wang. Multitask-based evaluation of open-source LLM on software vulnerability, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2404.02056</span>.</p>
</li>
<li data-list-text="[104]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -25pt; text-align: justify;"><a name="bookmark104"></a>&zwnj;Zhiqiang Yuan, Yiling Lou, Mingwei Liu, Shiji Ding, Kaixin Wang, Yixuan Chen, and Xin Peng. Evaluating and improving ChatGPT for unit test generation. <span class="s32">Proc. ACM Softw. Eng.</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3660783" target="_blank" rel="noopener">, 1(FSE):1703&ndash;1726, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3660783</span>.</p>
</li>
<li data-list-text="[105]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -25pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2307.12469" target="_blank" rel="noopener" name="bookmark105"> Cen Zhang, Mingqiang Bai, Yaowen Zheng, Yeting Li, Xiaofei Xie, Yuekang Li, Wei Ma, Limin Sun, and Yang Liu. Understanding large language model based fuzz driver generation, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2307.12469</span>.</p>
</li>
<li data-list-text="[106]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -24pt; text-align: justify;"><a name="bookmark106"></a>&zwnj;Chenyuan Zhang, Hao Liu, Jiutian Zeng, Kejing Yang, Yuhong Li, and Hui Li. Prompt-enhanced software vulnerability detection using ChatGPT. In <span class="s32">46th IEEE/ACM International Conference on Software Engineering: Companion Proceedings, ICSE Companion 2024, Lisbon, Portugal, April 14-20, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3639478.3643065" target="_blank" rel="noopener">, pages 276&ndash;277. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3639478.3643065</span>.</p>
</li>
<li data-list-text="[107]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -24pt; text-align: justify;"><a name="bookmark107"></a>&zwnj;Dylan Zhang, Xuchao Zhang, Chetan Bansal, Pedro Henrique B. Las-Casas, Rodrigo Fonseca, and Saravan Rajmohan. LM-PACE: confidence estimation by large language models for effective root causing of cloud incidents. In Marcelo d&rsquo;Amorim, editor, <span class="s32">Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering, FSE 2024, Porto de Galinhas, Brazil, July 15-19, 2024</span>, pages 388&ndash;398. ACM,</p>
<p style="padding-left: 31pt; text-indent: 0pt; line-height: 12pt; text-align: left;"><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3663529.3663858" target="_blank" rel="noopener">2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3663529.3663858</span>.</p>
</li>
<li data-list-text="[108]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -24pt; text-align: justify;"><a name="bookmark108"></a>&zwnj;Kexun Zhang, Danqing Wang, Jingtao Xia, William Yang Wang, and Lei Li. ALGO: synthesizing algorithmic programs with generated oracle verifiers. In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, <span class="s32">Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023</span>,</p>
<p style="padding-left: 31pt; text-indent: 0pt; text-align: left;">2023.</p>
</li>
<li data-list-text="[109]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -25pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2308.10022" target="_blank" rel="noopener" name="bookmark109">Ting Zhang, Ivana Clairine Irsan, Ferdian Thung, and David Lo. Cupid: Leveraging ChatGPT for more accurate duplicate bug report detection, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2308.10022</span>.</p>
</li>
<li data-list-text="[110]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -24pt; text-align: justify;"><a name="bookmark110"></a>&zwnj;Xuchao Zhang, Supriyo Ghosh, Chetan Bansal, Rujia Wang, Minghua Ma, Yu Kang, and Saravan Rajmohan. Automated root causing of cloud incidents using in-context learning with GPT-4. In Marcelo d&rsquo;Amorim, editor, <span class="s32">Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering, FSE 2024, Porto de Galinhas, Brazil, July 15-19, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3663529.3663846" target="_blank" rel="noopener">, pages 266&ndash;277. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3663529.3663846</span>.</p>
</li>
<li data-list-text="[111]">
<p style="padding-top: 8pt; padding-left: 31pt; text-indent: -25pt; text-align: justify;"><a style="color: black; text-decoration: none;" href="http://arxiv.org/abs/2310.00710" target="_blank" rel="noopener" name="bookmark111">Ying Zhang, Wenjia Song, Zhengjie Ji, Danfeng Yao, and Na Meng. How well does LLM generate security tests?, 2023,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">arXiv:2310.00710</span>.</p>
</li>
<li data-list-text="[112]">
<p style="padding-top: 8pt; padding-left: 30pt; text-indent: -24pt; text-align: justify;"><a name="bookmark112"></a>&zwnj;Xin Zhou, Ting Zhang, and David Lo. Large language model for vulnerability detection: Emerging results and future directions. In <span class="s32">Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results, NIER@ICSE 2024, Lisbon, Portugal, April 14-20, 2024</span><a style="color: black; text-decoration: none;" href="https://doi.org/10.1145/3639476.3639762" target="_blank" rel="noopener">, pages 47&ndash;51. ACM, 2024,&nbsp;</a><span style="color: black; font-family: Cambria, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt;">doi:10.1145/3639476.3639762</span>.</p>
</li>
</ol>
</body>
</html>